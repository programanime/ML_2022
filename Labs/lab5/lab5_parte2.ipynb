{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7h9z6smhTpe"
      },
      "source": [
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_VhwZwtm9I5"
      },
      "outputs": [],
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "in_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYer0hoGm9I6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not in_colab:\n",
        "    import sys ; sys.path.append('../commons/utils/'); sys.path.append('../commons/utils/data')\n",
        "else: \n",
        "    os.system('wget https://raw.githubusercontent.com/mariabda2/ML_2022/master/Labs/commons/utils/general.py -O general.py')\n",
        "    from general import configure_lab5_2\n",
        "    configure_lab5_2()\n",
        "from lab5 import *\n",
        "GRADER, dataset = part_2()\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59PRMgRphTpf"
      },
      "source": [
        "# Laboratorio 5 - Parte 2. Máquinas de Vectores de Soporte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbFfmXl-hTpi"
      },
      "source": [
        "## Ejercicio 1: Limipiar base de datos y completar código\n",
        "\n",
        "En este ejercicio usaremos la regresión por vectores de soporte para resolver el problema de regresión de la base de datos AirQuality (https://archive.ics.uci.edu/ml/datasets/Air+Quality). Tener en cuenta que vamos a usar solo 2000 muestras.\n",
        "\n",
        "En primera instancia vamos a transformar la matriz en un dataframe, para poderlo procesar de manera mas sencilla. Se crea una columna por cada variable que obtenemos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpuAUEFBm9I7"
      },
      "outputs": [],
      "source": [
        "dataset_df = pd.DataFrame(dataset, columns = [f'col_{c}' for c in range (1,14)])\n",
        "dataset_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPSDZfHIm9I8"
      },
      "source": [
        "Para esta base de datos vamos a realizar una limpieza de datos. \n",
        "\n",
        "Para ello vamos a completar la siguiente función:\n",
        "    \n",
        "1. **Remover** todos registros cuya variable objetivo es faltante (missing Value). Estos registros están marcados como -200, es decir, donde haya un valor -200 eliminaremos el registro.\n",
        "2. **imputar los valores perdidos/faltantes** en cada una de las características, vamos asuar la mediana de la característica en especifico.\n",
        "3. **Verificar** si quedaron valores faltantes\n",
        "4. **retornar**: X (12 primeras columnas) y Y(la 13 columna).\n",
        "Tips:\n",
        "1. Nuestra [sesión extra](https://mariabda2.github.io/ML_2022/Labs/Extra/Basic_Preprocessing_FeatureEngineering.html).\n",
        "2. Para transformar columnas de pandas a arreglos de numpy se puede usar `.iloc` / `.loc` y . `.values`, por ejemplo  para devolver una matriz con los valores de las primeras dos columnas es posible hacerlo asi: `dataset_df.iloc[: , 0:2].values` o `dataset_df.loc[: , ['col_1', 'col_2']].values`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBT8aPiihTpi"
      },
      "outputs": [],
      "source": [
        "# ejercicio de codigo\n",
        "def clean_data(df):\n",
        "    \"\"\"Función que limpia el dataset y obtiene X y Y.\n",
        "    \n",
        "    Argumentos:\n",
        "\n",
        "        df: es un pandas dataframe.\n",
        "    \n",
        "    Retorna:\n",
        "        X: una matriz numpy con los valores a usar como conjunto de datos\n",
        "        de entrada.\n",
        "        Y una matriz numpy con los valores usados como conjunto de datos\n",
        "        de salida.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # se copia el df para evitar cambios sobre el objeto\n",
        "    database = df.copy()\n",
        "\n",
        "    # Reemplazar por el valor correcto\n",
        "    VALOR_FALTANTE = ...\n",
        "    \n",
        "    ## Completar con la operación adecuada\n",
        "\n",
        "    pct_valores_faltantes = (database==-VALOR_FALTANTE)...()\n",
        "    # imprimir resumen\n",
        "    print(\",\".join([f\"% VF en {a}: {pct_valores_faltantes[a]*100:.2f}% \" for a in pct_valores_faltantes.index]))\n",
        "    \n",
        "    # identificar muestras cuya salida en un valor faltante\n",
        "\n",
        "    idx_to_remove = []\n",
        "    for idx in database.index:\n",
        "        ## reemplazar el valor adecuado\n",
        "        if database.iloc[idx, ...] == VALOR_FALTANTE:\n",
        "            idx_to_remove.append(idx)\n",
        "    \n",
        "    #remover la muestras de los indices\n",
        "    database = database.drop(idx_to_remove, axis = 0)\n",
        "\n",
        "    print (\"\\nHay \" + str(len(idx_to_remove)) + \" valores perdidos en la variable de salida.\")\n",
        "    print (\"\\nDim de la base de datos sin las muestras con variable de salida perdido \"+ str(np.shape(database)))\n",
        "\n",
        "    ## Imputar usando la estrategia adecuada.\n",
        "    print (\"\\nProcesando imputación de valores perdidos en las características . . .\")\n",
        "    imputer = ...(missing_values= ... , ...)\n",
        "    \"imputar solo las columnas de las variables de entrada\"\n",
        "    database.iloc[:, ... : ...] = imputer.fit_transform(database.iloc[:, ...] )\n",
        "\n",
        "    print (\"Imputación finalizada.\\n\")\n",
        "\n",
        "    ## Completar con la operación adecuada\n",
        "    pct_valores_faltantes = (database==...)...()\n",
        "    \n",
        "    print(\",\".join([f\"% VF en {a}: {pct_valores_faltantes[a]*100:.2f}% \" for a in pct_valores_faltantes.index]))\n",
        "    \n",
        "    if(pct_valores_faltantes.max() != 0):\n",
        "        print (\"Hay valores perdidos\")\n",
        "    else:\n",
        "        print (\"No hay valores perdidos en la base de datos. Ahora se puede procesar\")\n",
        "\n",
        "    X = database.iloc[:, ... : ...].values\n",
        "    Y = database.iloc[:, ... : ...].values\n",
        "    return (X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_aHK7XThTpk"
      },
      "outputs": [],
      "source": [
        "# Ignorar los prints.\n",
        "GRADER.run_test(\"ejercicio1\", clean_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_siuGCthTpm"
      },
      "source": [
        "Ahora usemos la función para tener nuestras variables X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJLs3jUohTpm"
      },
      "outputs": [],
      "source": [
        "X,Y = clean_data(dataset_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfT-7D5AhTpo"
      },
      "source": [
        "## Ejercicio 2: Experimentar SVM para regresión\n",
        " \n",
        "Ahora vamos a crear la función para experimentar con la máquina de soporte vectorial con las siguientes especificaciones:\n",
        " \n",
        "1. Usar la librería de sklearn https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html.\n",
        "2. Variar tres parámetros del SVR: kernel,  gamma y el parámetro de regularización.\n",
        "3. Utilizar la metodología de validación cruzada con 5 folds.\n",
        "4. Usar normalización de datos estándar implementada por sklearn\n",
        "5. Extraer los vectores de soporte (observe los *atributos* del modelo SVR de sklearn). Recuerde que estos atributos pueden ser accedidos, una vez el modelo es entrenado.\n",
        "6. Utilizar la métrica para calcular el MAPE (usar sklearn).\n",
        " \n",
        "**Notas**:\n",
        "- Deberíamos poder acceder a las funciones de la librería de sklearn directamente por el nombre sin necesidad de importarlas. Las funciones que deberías utilizar ya están precargadas en la configuración del laboratorio.\n",
        "\n",
        "- Llame todos los parámetros de las funciones de sklearn de manera explícita. (i.e, si se quiere usar `max_iter` como parámetro para el SVR, debe crear el objeto: `SVR(max_iter = 100)`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84KNyMMuhTpp"
      },
      "outputs": [],
      "source": [
        "#ejercicio de código\n",
        "def experiementarSVR(x, y, kernels, gammas,params_reg):\n",
        "    \"\"\"función que realizar experimentos sobre un SVM para regresión\n",
        "    \n",
        "    Argumentos\n",
        "        x: numpy.Array, con las caracteristicas del problema\n",
        "        y: numpy.Array, con la variable objetivo\n",
        "        kernels: List[str], lista con valores a pasar \n",
        "            a sklearn correspondiente al kernel de la SVM\n",
        "        gammas: List[float], lista con los valores a pasar a\n",
        "            sklean correspondiente el valor de los coeficientes para usar en el\n",
        "            kernel\n",
        "        params_reg: List[float], lista con los valores a a pasar a \n",
        "            sklearn para ser usados como parametro de regularización\n",
        "    retorna: \n",
        "        pd.Dataframe con los resultados.\n",
        "    \"\"\"\n",
        "    idx = 0\n",
        "    kf = KFold(n_splits= ... )\n",
        "    # crear una lista con la combinaciones de los elementos de cada lista.\n",
        "    kernels_gammas_regs = list(itertools.product(kernels, gammas, params_reg))\n",
        "    resultados = pd.DataFrame()\n",
        "    \n",
        "    for params in kernels_gammas_regs:\n",
        "        kernel, gamma, param_reg = params\n",
        "        print(\"parametros usados\", params) # puede usar para ver los params\n",
        "        rendimiento_test = []\n",
        "        pct_support_vectors = []\n",
        "        num_support_vectors = []\n",
        "        for train_index, test_index in kf.split(x):\n",
        "            \n",
        "            X_train, X_test = x[train_index], x[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]  \n",
        "            # normalizar los datos\n",
        "            scaler = ... ()\n",
        "            X_train = scaler... (X=...)\n",
        "            X_test = scaler.... (X=...)\n",
        "            svm = ... ( )\n",
        "            # Entrenar el modelo\n",
        "            svm... (X=... , y=...)\n",
        "            # Validación del modelo\n",
        "            ypred = svm.... (X=...)\n",
        "            \n",
        "            # error y pct de vectores de soporte\n",
        "            rendimiento_test.append(... (...  = .... , ... = ...))\n",
        "            # contar muestras de entrenamiento\n",
        "            n_train = ... \n",
        "            num_vs = len(svm...)\n",
        "            pct_vs = (num_vs/ n_train ) *100\n",
        "            pct_support_vectors.append(pct_vs)\n",
        "            num_support_vectors.append(num_vs)\n",
        "        \n",
        "        resultados.loc[idx,'kernel'] = ...\n",
        "        resultados.loc[idx,'gamma'] = ...\n",
        "        resultados.loc[idx,'param_reg'] = ... \n",
        "        resultados.loc[idx,'Métrica de de rendimiento'] = np... (rendimiento_test)\n",
        "        resultados.loc[idx,'Desviación estandar en métrica de de rendimiento'] = np... (rendimiento_test)\n",
        "        resultados.loc[idx,'# de vectores de soporte'] = np.mean(...)\n",
        "        resultados.loc[idx,'% de vectores de soporte'] = np.mean(...)\n",
        "        \n",
        "        idx+=1\n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB4bMhUhhTpr"
      },
      "outputs": [],
      "source": [
        "GRADER.run_test(\"ejercicio2\", experiementarSVR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aatsj0EQhTpt"
      },
      "source": [
        "Para entrenar vamos a ignorar las dos primeras variables, estas corresponden a valores de fechas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRHwQhR7hTpu"
      },
      "outputs": [],
      "source": [
        "# vamos a realizar los experimentos.\n",
        "resultadosSVR = experiementarSVR(x =X[:,2:],y=Y,\n",
        "                                 kernels=['linear', 'rbf'],\n",
        "                                 gammas = [0.01,0.1],\n",
        "                                 params_reg = [0.1, 1.0,10]\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEPmKLZhhTpw"
      },
      "outputs": [],
      "source": [
        "# ver los 5 primeros resultados\n",
        "resultadosSVR.sort_values('Métrica de de rendimiento',ascending=True).head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssBHGAr0ZBZU"
      },
      "outputs": [],
      "source": [
        "# Ver los 5 peores modelos\n",
        "# ver los 5 primeros resultados\n",
        "resultadosSVR.sort_values('Métrica de de rendimiento',ascending=False).head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qERAELnQhTpx"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cual es el objetivo de las las funciones kernel? Contestar dentro del contexto de las máquinas de sporte vectorial.\n",
        "respuesta_1 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wCsV08SCm9JB"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown Explique en sus palabras ¿cual es la relación tienen los vectores de soporte y el epsilon-tubo?\n",
        "respuesta_2 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X37FqhDQhTp0"
      },
      "source": [
        "Para analizar los resultados comparando el mejor y el peor modelo encontrado, usando dos graficas:\n",
        "\n",
        "1. Grafica donde el eje x es el valor real y eje y el valor predicho.\n",
        "2. Grafica donde el eje x vamos a dejar un valor incremental y con colores vamos a diferenciar entre el valor real y el valor predicho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Jzv6uhjZBZW"
      },
      "outputs": [],
      "source": [
        "# dividir el conjunto para estas graficas\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "#predicciones\n",
        "# OJO: Reemplazar los valores!\n",
        "YpredBest =  predict_svr(X_train, y_train, X_test, y_test, kernel = ... , gamma = ... , param_reg = ...)\n",
        "YpredWorst = predict_svr(X_train, y_train, X_test, y_test, kernel = ... , gamma = ... , param_reg = ... )\n",
        "# verificar en el print que el error sea diferente y concuerde con el entendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S6KsCkihTp1"
      },
      "outputs": [],
      "source": [
        "# plots\n",
        "f, ax = plt.subplots(nrows=1, sharex=False, sharey=False, figsize = (16,8))\n",
        "# Mejor Modelo.\n",
        "ax.scatter(y_test, YpredBest, label = 'Mejor Modelo')\n",
        "ax.scatter(y_test, YpredWorst, label = 'Peor Modelo', c='r')\n",
        "ax.plot(y_test, y_test, label = 'Modelo perfecto', c='k', alpha=0.5)\n",
        "ax.set_xlabel('valor real', fontdict = {'fontsize': 12})\n",
        "ax.set_ylabel('valor predicho', fontdict = {'fontsize': 12})\n",
        "ax.set_title(\"Mejor modelo vs Peor modelo\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0wploEQHhTp3"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Analizando de manera cualitativa la gráfica?\n",
        "#@markdown ¿Cuál de las afirmaciones está mejor justificada?\n",
        " \n",
        "#@markdown A) En los dos modelos se observa una relación lineal, sin embargo el \"peor\" modelo tiene mayores diferencias en los valores extremos (cercanos a 0.4 y mayores que 1.4).\n",
        " \n",
        "#@markdown B) En los dos modelos se observa una relación lineal, sin embargo el \"mejor\" modelo tiene mayores diferencias al observar los valores extremos (cercanos a 0.4 y mayores que 1.4).\n",
        " \n",
        "#@markdown C) En los dos modelos se observa una relación lineal,  no es posible determinar diferencias ya que se esperaba que \"peor\" modelo no tuviera una relación lineal.\n",
        " \n",
        "#@markdown D) Se observa que en los valores centrales, la diferencia no es mucha, las diferencias se ven en los valores extremos que pueden ser catalogados como \"outliers\", por lo tanto no hay una diferencia significativa en los dos modelos.\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_3 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3wpsNgJZBZX"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(nrows=2, sharex=False, sharey=False, figsize = (16,8))\n",
        "#  Mejor Modelo\n",
        "ax[0].plot(y_test, label = 'valor real', color = 'b', alpha = 0.7)\n",
        "ax[0].plot(YpredBest, label = 'valor predicho mejor modelo', color = 'r',linestyle='dashed', alpha = 0.5)\n",
        "ax[0].legend()\n",
        "ax[0].set_ylabel('Humedad relativa', fontdict = {'fontsize': 12})\n",
        "#  Peor Modelo\n",
        "ax[1].plot(y_test, label = 'valor real', color = 'b', alpha = 0.7)\n",
        "ax[1].plot(YpredWorst, label = 'valor predicho peor modelo', color = 'r',linestyle='dashed', alpha = 0.5)\n",
        "ax[1].legend()\n",
        "ax[1].set_ylabel('Humedad relativa', fontdict = {'fontsize': 12})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y0qtgwGDZBZX"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Analizando de manera cualitativa las gráficas?\n",
        "#@markdown ¿Cuál de las afirmaciones está mejor justificada?\n",
        " \n",
        "#@markdown A) En el \"peor\" modelo se observa menores diferencias, en ciertas partes de la gráfica se puede diferenciar las dos líneas de manera muy clara. En el \"mejor\" modelo también ocurren estas diferencias, pero los valores están más alejados.\n",
        " \n",
        "#@markdown B) Ningún modelo puede resolver bien el problema, debemos seguir entrenando hasta lograr que los valores predichos no se logren diferenciar del valor real.\n",
        " \n",
        "#@markdown C) En el \"mejor\" modelo se observa mayores diferencias, en ciertas partes de la gráfica se puede diferenciar las dos líneas de manera muy clara. En el \"peor\" modelo también ocurren estas diferencias, pero los valores son más cercanos.\n",
        " \n",
        "#@markdown D) En el \"peor\" modelo se observa mayores diferencias, en ciertas partes de la gráfica se puede diferenciar las dos líneas de manera muy clara. En el \"mejor\" modelo también ocurren estas diferencias, pero los valores son más cercanos.\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_4 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzJklaaBhTp5"
      },
      "source": [
        "## Ejercicio 3: Experimentar SVM para clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDd9cs8YhTp5"
      },
      "source": [
        "En este ejercicio vamos a volver a resolver el problema de clasificación de dígitos. Vamos usar solo 5 clases y realizaremos un pre-procesamiento:\n",
        "1. mediante PCA (una tecnica proxima a practicar en el laboratorio)\n",
        "2. Vamos a convertirlo en problema de tres clases (vamos a diferenciar entre 0, 1 y el resto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK18YvtnhTp5"
      },
      "outputs": [],
      "source": [
        "Xcl, Ycl = load_digits(n_class=5,return_X_y=True)\n",
        "#--------- preprocesamiento--------------------\n",
        "pca = PCA(0.99, whiten=True)\n",
        "Xcl = pca.fit_transform(Xcl)\n",
        "# cambiar problema de clases\n",
        "unique, counts  = np.unique(Ycl, return_counts=True)\n",
        "print(\"distribución original (claves las etiquetas, valores el número de muestras): \\n\", dict(zip(unique, counts )))\n",
        "Ycl = np.where(np.isin(Ycl, [0,1]), Ycl, 2)\n",
        "unique, counts  = np.unique(Ycl, return_counts=True)\n",
        "print(\"Nueva distribución  (claves las etiquetas, valores el número de muestras): \\n\", dict(zip(unique, counts )))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9AsO_TrhTp7"
      },
      "source": [
        "Ahora vamos a crear la función para experimentar con la maquina de soporte vectorial para un problema de clasificación. Para ello vamos a:\n",
        "\n",
        "1. Usar la libreria de sklearn https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
        "2. Variar tres parámetros del SVC: kernel,  gamma y el parametro de regularización.\n",
        "3. Utilizar la metodología cross-validation con 4 folds más adecuada para problemas de clasificación.\n",
        "4. Usar la normalización de datos estandar implementada por sklearn.\n",
        "5. Extraer los vectores de soporte (observe los *atributos* del modelo SVC de sklearn). Recuerde que estos atributos son accesibles una vez el modelo es entrenado\n",
        "6. vamos a probar la dos estragegias del SVC:\n",
        "    - One Vs One\n",
        "    - One Vs Rest\n",
        "7. Utilizar como error el score de exactitud de la clasificación de sklearn.\n",
        "\n",
        "**Notas**: \n",
        "- Deberiamos poder acceder a las funciones de la libreria de sklearn directamente por el nombre sin necesidad de importarlas. Las funciones que deberios utilizar ya están precargadas en la configuración del laboratorio.\n",
        "- Llame todos los parametros de las funciones de sklearn de manera explicita. (i.e, si se quiere usar `max_iter` como parámetro para el SVC, debe crear el objeto: `SVC(max_iter = 100)`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggnW0A7hm9JD"
      },
      "source": [
        "* sklearn tiene unos \"wrappers\", que implementan estrategias para la clasificación multiclase, uno  de estos wrappers, implementa la estrategia one-vs-rest: https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html.\n",
        "\n",
        "* Un wrapper, es un esquema de diseño común para \"envolver\" librerias/funciones con caracteristicas similares y poder modificar ciertos comportamientos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHpENPahhTp7"
      },
      "outputs": [],
      "source": [
        "#ejercicio de código\n",
        "def experiementarSVC(x, y, kernels, gammas,params_reg, estrategia = 'ovo'):\n",
        "    \"\"\"función que realizar experimentos sobre un SVM para clasificación\n",
        "    \n",
        "    x: numpy.Array, con las caracteristicas del problema\n",
        "    y: numpy.Array, con la variable objetivo\n",
        "    kernels: List[str], lista con valores a pasar \n",
        "        a sklearn correspondiente al kernel de la SVM\n",
        "    gammas: List[float], lista con los valores a pasar a\n",
        "        sklean correspondiente el valor de los coeficientes para usar en el\n",
        "        kernel\n",
        "    params_reg: List[float], lista con los valores a a pasar a \n",
        "        sklearn para ser usados como parametro de regularización\n",
        "    estrategia: str, valor que puede ser ovo (para one vs one) o ovr \n",
        "        (para one vs rest)\n",
        "    \n",
        "    retorna: \n",
        "        pd.Dataframe con el resultado de los experimentos.\n",
        "    \"\"\"\n",
        "    idx = 0\n",
        "    kf = ... (n_splits= ... )\n",
        "    # crear una lista con la combinaciones de los elementos de cada list\n",
        "    kernels_gammas_regs = list(itertools.product(kernels, gammas, params_reg))\n",
        "    resultados = pd.DataFrame()\n",
        "    \n",
        "    for params in kernels_gammas_regs:\n",
        "        kernel, gamma, param_reg = params\n",
        "        print(\"parametros usados\", params) # puede usar para ver los params\n",
        "        rendimiento_train = []\n",
        "        rendimiento_test = []\n",
        "        pct_support_vectors = []\n",
        "        \n",
        "        for train_index, test_index in kf.split(X = ... , y = ... ):\n",
        "            X_train, X_test = x[train_index], x[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]  \n",
        "            # normalizar los datos\n",
        "            scaler = ... ()\n",
        "            X_train = scaler.... (X = X_train)\n",
        "            X_test = scaler... (X = X_test)\n",
        "            \n",
        "            svm = ... (...)\n",
        "            \n",
        "            # si es estrategia \"envolver\" a la svm\n",
        "            if estrategia =='ovr':\n",
        "                svm = ... (svm)               \n",
        "            \n",
        "            # Entrenar el modelo\n",
        "            svm.fit(X=X_train, y=y_train)\n",
        "            # calculo de errores\n",
        "            y_train_pred = svm... (X=... )\n",
        "            y_test_pred = svm... (X=...)\n",
        "            # error y pct de vectores de soporte\n",
        "            rendimiento_train.append(... (y_true = y_train, y_pred = y_train_pred))\n",
        "            rendimiento_test.append(... (y_true = y_test, y_pred = y_test_pred))\n",
        "            # contar muestras de entrenamiento\n",
        "            n_train = ...\n",
        "            if estrategia == 'ovr':\n",
        "                # en esta estrategia se realizar una SVM por cada clase\n",
        "                # por lo tanto tenemos que acceder a cada una de la\n",
        "\n",
        "                num_vs = np.mean([len(svc...) for svc in svm.estimators_])\n",
        "                pct_vs = (num_vs/n_train)*100\n",
        "                \n",
        "            else:\n",
        "                pct_vs = (len(svm.support_)/n_train)*100\n",
        "            pct_support_vectors.append(pct_vs)\n",
        "        \n",
        "        resultados.loc[idx,'kernel'] = ...\n",
        "        resultados.loc[idx,'gamma'] = ...\n",
        "        resultados.loc[idx,'param_reg'] = ...\n",
        "        resultados.loc[idx,'estrategia'] = ... \n",
        "        resultados.loc[idx,'Métrica de de rendimiento entrenamiento'] = np... (rendimiento_train)\n",
        "        resultados.loc[idx,'Métrica de de rendimiento prueba'] = np... (rendimiento_test)\n",
        "        resultados.loc[idx,'% de vectores de soporte'] = np... (pct_support_vectors)\n",
        "        idx+=1\n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPY9emZGhTp-"
      },
      "outputs": [],
      "source": [
        "GRADER.run_test(\"ejercicio3\", experiementarSVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtuL_Gunm9JE"
      },
      "source": [
        "Veamos la estrategia OVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLwkxs1fhTp_"
      },
      "outputs": [],
      "source": [
        "# vamos a realizar los experimentos\n",
        "resultadosSVC_ovr = experiementarSVC(x = Xcl,y=Ycl,\n",
        "                                 kernels=['linear', 'rbf'],\n",
        "                                 gammas = [0.01,0.1],\n",
        "                                 params_reg = [0.001, 0.01,0.1, 1.0,10],\n",
        "                                estrategia = 'ovr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpbX_1N2m9JE"
      },
      "outputs": [],
      "source": [
        "# ver los mejores modelos\n",
        "resultadosSVC_ovr.sort_values('Métrica de de rendimiento prueba', ascending=False).head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMLzgKVhm9JE"
      },
      "source": [
        "Ahora vamos a ver la estrategia OVO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BPy6leLm9JE"
      },
      "outputs": [],
      "source": [
        "# vamos a realizar los experimentos\n",
        "resultadosSVC_ovo = experiementarSVC(x = Xcl,y=Ycl,\n",
        "                                 kernels=['linear', 'rbf'],\n",
        "                                 gammas = [0.01,0.1],\n",
        "                                 params_reg = [0.001, 0.01,0.1, 1.0,10],\n",
        "                                estrategia = 'ovo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eWC6Xj4m9JE"
      },
      "outputs": [],
      "source": [
        "# ver los mejores modelos\n",
        "resultadosSVC_ovo.sort_values('Métrica de de rendimiento prueba', ascending=False).head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YcGKqkW8hTqB"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown Explique en sus palabras ¿qué representan los vectores de soporte en un problema de clasificación?\n",
        "respuesta_5 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lee35iFeZBZZ"
      },
      "outputs": [],
      "source": [
        " \n",
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cual otra métrica del módulo de sklearn podría ser usada?\n",
        "#@markdown ¿Cuál de las afirmaciones está mejor justificada?\n",
        " \n",
        "#@markdown A) Por ser un problema de clasificación sin importar el balance de clases, el `accuracy_score` es adecuado, pero se podría usar también `f1_score` por ser un problema binario.\n",
        " \n",
        "#@markdown B) Por ser un problema de clasificación desbalanceado  `matthews_corrcoef` y `balanced_accuracy_score` son más adecuadas.\n",
        " \n",
        "#@markdown C) Por ser un problema de clasificación desbalanceado `accuracy_score` es adecuada, pero se podría usar también `f1_score` y `confusion_matrix`.\n",
        " \n",
        "#@markdown D) Por ser un problema de clasificación desbalanceado  `matthews_corrcoef`, `balanced_accuracy_score` y `G_mean` son más adecuadas.\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_6 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta2szRQRhTqE"
      },
      "outputs": [],
      "source": [
        "# ver la relación de parametro de regularización y los vectores de soporte\n",
        "ax = sns.relplot(data = resultadosSVC_ovo, x = 'param_reg', y = '% de vectores de soporte', kind = 'line', col ='kernel', aspect = 1.5)\n",
        "ax.set(xscale=\"log\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pPGG4r9ShTqG"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿qué relación observa entre el valor del parametro de regularización y los vectores de soporte? ¿como puede ser explicada esta relación?\n",
        "respuesta_7 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnTq9RTehTqH"
      },
      "outputs": [],
      "source": [
        "GRADER.check_tests() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dQ-WZCK-hTqJ"
      },
      "outputs": [],
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va7hyAs6hTqK"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek0GsP_0hTqL"
      },
      "outputs": [],
      "source": [
        "GRADER.grade()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab5_parte2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('udea')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c216c800eb90efed5b4e7fbe9fb3a04a2ffbc3fe33e223430d52baede0ec7928"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}