{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrfDiFHOUHIf"
      },
      "source": [
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQYGVnUWLp4W"
      },
      "outputs": [],
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "in_colab = True\n",
        "import os\n",
        "\n",
        "if not in_colab:\n",
        "    import sys ; sys.path.append('../commons/utils/');\n",
        "else: \n",
        "    os.system('wget https://raw.githubusercontent.com/mariabda2/ML_2022/master/Labs/commons/utils/general.py -O general.py')\n",
        "    from general import configure_lab5_1\n",
        "    configure_lab5_1()\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('INFO')\n",
        "import seaborn as sns\n",
        "from lab5 import *\n",
        "GRADER = part_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpINIvigUHIj"
      },
      "source": [
        "# Laboratorio 5 - Parte 1. Redes recurrentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juJzpTmIUHIj"
      },
      "source": [
        "En este laboratorio vamos a explorar la creación de redes recurrentes (RNN). De Igual manera vamos a explorar algunas funcionalidades de [la librería TensorFlow](https://www.tensorflow.org/). Recordemos que esta librería es uno de los estándares para entrenar redes neuronales e implementa varios de los conceptos y mejoras de Deep Learning. Este laboratorio sirve como un abrebocas para esta librería, ya que esta tiene muchas funcionalidades que no vamos a explorar en profundidad.\n",
        " \n",
        "Las RNN son diseñadas para resolver problemas donde nuestros datos tienen un orden o una secuencia. Un tipo de estos problemas, son problemas de series de tiempo. Para este laboratorio vamos usar un [conjunto de datos de clima](https://www.bgc-jena.mpg.de/wetter/) el cual fue recolectado por el [instituto Max Planck](https://www.bgc-jena.mpg.de/). Este conjunto de datos contiene 14 características como la temperatura del aire, la presión atmosférica y humedad, los cuales fueron medidos cada 10 minutos desde el 2003. Para aumentar la eficiencia, solo usaremos muestras entre 2012 y 2016.\n",
        " \n",
        "Este laboratorio usa algunas ideas presentadas [en este tutorial publicado en la página de tensorflow](https://www.tensorflow.org/tutorials/structured_data/time_series). La invitación es que puedas explorar este tutorial luego de desarrollar esta guía.\n",
        "\n",
        "Vamos a descargar el conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFVIZJdYLp4Y"
      },
      "outputs": [],
      "source": [
        "# Referenciar el link con el procesamiento de datos.\n",
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOMjA1OyLp4Z"
      },
      "source": [
        "Como se mencionó el conjunto de datos tiene muestras cada 10 minutos y 14 variables. En la siguiente celda cargaremos el conjunto de datos y aplicaremos dos restricciones que nos ayudarán a facilitar el problema.\n",
        " \n",
        "1. Usaremos muestras de cada hora, en lugar de usar las muestras con la frecuencia de 10 minutos original.\n",
        "2. Filtramos a partir del año 2012. \n",
        "3. Usaremos solo una variable: `T (degC)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYFf6PqRLp4Z"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "# Aplicamos el siguiente slice [start:stop:step]. \n",
        "# Significa tomaremos intervalos cada 6 pasos. \n",
        "#  Esto quiere decir tomar puntos cada hora\n",
        "df = df[5::6]\n",
        "# Transformamos la columna de fecha.\n",
        "# Usamos las fechas como indice.\n",
        "df.index =  pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n",
        "onwards_2012 = (df.index.year >= 2012)\n",
        "df = df.loc[onwards_2012, ['T (degC)']].copy()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Uw2aZ7lLp4Z"
      },
      "source": [
        "En la siguiente celda visualizamos los datos. Debemos observar el aparente periodo que existe en nuestra variable. ¿cada cuantos puntos parece repertirse el patrón de la serie?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFwjW5EKLp4Z"
      },
      "outputs": [],
      "source": [
        "plot_cols = ['T (degC)']\n",
        "plot_features = df[plot_cols]\n",
        "_ = plot_features.plot(subplots=True, figsize = (15,6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_ECDM60Lp4a"
      },
      "source": [
        "Hacemos un acercamiento en diferentes fechas, para ver los ciclos diarios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tIllCJOLp4a"
      },
      "outputs": [],
      "source": [
        "enero_2012 = (df.index.month == 1) & (df.index.year == 2012) \n",
        "plot_features = df.loc[enero_2012, plot_cols]\n",
        "_ = plot_features.plot(subplots=True, figsize = (15,6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS-FfD0gLp4a"
      },
      "outputs": [],
      "source": [
        "junio_2014 = (df.index.month == 6) & (df.index.year == 2014) \n",
        "plot_features = df.loc[junio_2014, plot_cols]\n",
        "_ = plot_features.plot(subplots=True, figsize = (15,6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0u19e8LUHIn"
      },
      "source": [
        "En nuestro primer ejercicio vamos a explorar, el patrón que observamos en la grafica anterior.\n",
        "\n",
        "La librería statsmodel [tiene una función que nos sirve para analizar esta relación](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html).\n",
        "\n",
        "\n",
        "## Ejercicio 1 - Exploración del problema\n",
        "\n",
        "Esta función realiza una operación cuyos detalles son explicados en mayor profundidad en [esta buena entrada de blog](https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/). En  nuestro laboratorio lo que no interesa entender:\n",
        "\n",
        "1. El valor varia entre 1.0 y -1.0. \n",
        "2. Cuando el valor de la correlación es 1.0, corresponde el valor maximo indicando una relación positiva entre la variable y su correspondiente lag o retraso.\n",
        "3. Cuando el valor de la correlación es -1.0, corresponde el valor mínimo indicando una relación negativa entre la variable y su correspondiente lag o retraso.\n",
        "4. 0.0 indica que los valores no están relacionados.\n",
        "5. El eje X indica el número de retrasos. Si el valor de la correlación en el lag  5 es igual 0.75, indica una relación positiva alta entre el quinto retraso anterior en la mayoria de muestras de nuestra variable objetivo.\n",
        "\n",
        "Ahora, grafiquemos la auto-correlación. Observa las variables `dias_to_plot` y `horas_dia`.  Puedes variar los valores de estas variables y observar como cambia la grafica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFanVFDdUHIn"
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics import tsaplots\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (18,6))\n",
        "dias_to_plot = 15\n",
        "horas_dia = 24\n",
        "TOTAL_MUESTRAS = dias_to_plot*horas_dia\n",
        "rango = list(range(1,TOTAL_MUESTRAS, horas_dia))\n",
        "# Muestra la aucorrelación de la serie de tiempo.\n",
        "fig = tsaplots.plot_acf(df[plot_cols], lags=range(1, TOTAL_MUESTRAS), ax = ax)\n",
        "# Grafica indicadores para observar el patros\n",
        "ax.scatter(rango , 0.75*np.ones(dias_to_plot), c = 'r', marker = \"v\")\n",
        "ax.set_xticks(rango,  [f'ciclo {int(c/horas_dia)}\\n de 24 lags' for c in rango])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CWoMbcjUHIp"
      },
      "source": [
        "Reforzando el entendimiento, observando la gráfica anterior:\n",
        " \n",
        "1. Los lags varían entre 0 y 24, es decir evaluamos que tan relacionado está el valor \"presente\" con las muestras de 1,2,3,..., hasta 24 horas , tenemos una autocorrelación que comienza alta ($\\approx 1$) y va decreciendo hasta $\\approx 0.75$.\n",
        "2. Luego del lag 25, otro ciclo parece repetirse, pero los valores de autocorrelación son más bajos que en el primer ciclo.\n",
        "3. Se observa un ciclo cada 24 puntos, pero por cada nuevo ciclo el valor de la autocorrelación disminuye, por ejemplo para el \"ciclo 10\" el valor máximo de autocorrelación ya está por debajo de 0.75. **PISTA**: ¿que tan relacionada está la temperatura de el dia de *hoy* con la temperatura de hace 10 días? ¿Esta relación es mayor o menor que la temperatura de hace 24 horas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtkUurhkLp4b"
      },
      "source": [
        "De acuerdo a la interpretación de la anterior grafica responde la siguiente pregunta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M24ZNi_PLp4b"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cual podria ser el número minimo de muestras pasadas/retrasos que estan relacionados con el valor presente?\n",
        "respuesta_1 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgZ1nA587d3c"
      },
      "source": [
        "Como sabemos de nuestra teoría, para poder aplicar RNN a una serie de tiempo debemos transformar nuestro datos en alguno de los siguientes problemas:\n",
        " \n",
        "1. one to one\n",
        "2. one to many\n",
        "3. many to one\n",
        "4. many to many\n",
        " \n",
        "La siguiente función usa algunas de las funcionalidades de TensorFlow, para transformar los datos para transformar nuestro conjunto de datos en alguno de los anteriores tipo de problema. \n",
        "\n",
        "Explora un poco el codigo, pero en la siguientes celdas vamos a entender los efectos practicos de las funciones.\n",
        "\n",
        "**NOTA**: Para este laboratorio, vamos enfocarnos más en el efecto practico de la función y no necesitas entender en profundidad las diferentes funcionalidades de la libreria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSks6iflLp4c"
      },
      "outputs": [],
      "source": [
        "class WindowGenerator():\n",
        "    def __init__(self, input_width, label_width, shift,\n",
        "                train_df=None, \n",
        "                test_df=None,\n",
        "                label_columns=plot_cols):\n",
        "        self.train_df = train_df\n",
        "        self.test_df = test_df\n",
        "\n",
        "        self.label_columns = label_columns\n",
        "        self.label_columns_indices = {name: i for i, name in\n",
        "                                      enumerate(label_columns)}\n",
        "        self.column_indices = {name: i for i, name in\n",
        "                              enumerate(train_df.columns)}\n",
        "\n",
        "        self.input_width = input_width\n",
        "        self.label_width = label_width\n",
        "        self.shift = shift\n",
        "\n",
        "        self.total_window_size = input_width + shift\n",
        "\n",
        "        self.input_slice = slice(0, input_width)\n",
        "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "        self.label_start = self.total_window_size - self.label_width\n",
        "        self.labels_slice = slice(self.label_start, None)\n",
        "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '\\n'.join([\n",
        "            f'Total tamaño de la ventana: {self.total_window_size}',\n",
        "            f'Inidice de entrada: {self.input_indices}',\n",
        "            f'Indice a predicir: {self.label_indices}'])\n",
        "\n",
        "def split_window(self, features=None, with_example= False):\n",
        "    if with_example:\n",
        "        # definir un Ejemplo.\n",
        "        features = tf.stack([np.array(self.train_df[:self.total_window_size]),\n",
        "                           np.array(self.train_df[100:100+self.total_window_size]),\n",
        "                           np.array(self.train_df[200:200+self.total_window_size])])\n",
        "    inputs = features[:, self.input_slice, :]\n",
        "    labels = features[:, self.labels_slice, :]\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "    # configurar nuevamente el shape del vector.\n",
        "    inputs.set_shape([None, self.input_width, None])\n",
        "    labels.set_shape([None, self.label_width, None])\n",
        "    # asignar como ejemplos\n",
        "    if with_example:\n",
        "        self.example = inputs, labels\n",
        "        \n",
        "    return inputs, labels\n",
        "\n",
        "def plot(self, plot_col='T (degC)', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "      plt.subplot(max_n, 1, n+1)\n",
        "      plt.ylabel(f'{plot_col}')\n",
        "      plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "              label='Entradas', marker='.', zorder=-10)\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "      plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                  edgecolors='k', label='Salida(s)', c='b', s=64)\n",
        "      if n == 0:\n",
        "        plt.legend()\n",
        "\n",
        "# adicionar el metodo a clase.\n",
        "WindowGenerator.split_window = split_window\n",
        "# Adicionar el metodo a la clase\n",
        "WindowGenerator.plot = plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7WCZuaZLp4c"
      },
      "source": [
        "La siguiente celda codigo muestra el ejemplo de usar la función para generar muestras que usen seis puntos (ultimas seis horas), para predecir la siguiente hora.\n",
        "\n",
        "![Imagen split window](https://www.tensorflow.org/static/tutorials/structured_data/images/split_window.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nWrYcaKLp4c"
      },
      "outputs": [],
      "source": [
        "w1 = WindowGenerator(train_df = df, input_width=6, label_width=1, shift=1)\n",
        "w1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3PyEMQxLp4c"
      },
      "outputs": [],
      "source": [
        "w1.split_window(with_example=True)\n",
        "w1.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7-qpEukLp4d"
      },
      "source": [
        "El anterior ejemplo transforma nuestro conjunto de datos en un problema `many-to-one`. Estamos usandos seis muestras, para predecir una muestra en el futuro. Ejecuta, analiza la siguiente celda y responde la pregunta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8FGyAMtLp4d"
      },
      "outputs": [],
      "source": [
        "w1 = WindowGenerator(train_df = df, input_width=24, label_width=24, shift=24)\n",
        "print(w1)\n",
        "w1.split_window(with_example=True)\n",
        "w1.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gyjTcwJxLp4d"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Analizando los parametros `input_width`, `label_width` y `shift` de `WindowGenerator`?\n",
        "#@markdown ¿Cual de las opciones está mejor justificada?\n",
        " \n",
        "#@markdown A) Usar `input_width=1, label_width=24, shift=24` representa un problema `one-to-one` y `input_width=24, label_width=24, shift=24` un problema `many-to-many`.\n",
        " \n",
        "#@markdown B) Usar `input_width=1, label_width=24, shift=24` representa un problema `one-to-many` y `input_width=24, label_width=24, shift=24` un problema `many-to-many`.\n",
        " \n",
        "#@markdown C) Usar `input_width=2, label_width=24, shift=24` representa un problema `one-to-many` y `input_width=24, label_width=24, shift=24` un problema `many-to-many`.\n",
        " \n",
        "#@markdown D) Usar `input_width=1, label_width=24, shift=24` y `input_width=24, label_width=24, shift=24` representan un problema `many-to-many`.\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_2 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTO4PLx2Lp4d"
      },
      "source": [
        "En Tensorflow, se debe crear de manera eficiente los conjuntos de datos, la siguiente celda, crea unos metodos que nos van ayudar a realizar este operación, usando la función que ya comprendimos anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEhuhpPPLp4d"
      },
      "outputs": [],
      "source": [
        "def make_dataset(self, data):\n",
        "    data = np.array(data, dtype=np.float32)\n",
        "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "        data=data,\n",
        "        targets=None,\n",
        "        sequence_length=self.total_window_size,\n",
        "        sequence_stride=1,\n",
        "        shuffle=True,\n",
        "        batch_size=32,)\n",
        "\n",
        "    ds = ds.map(self.split_window)\n",
        "\n",
        "    return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset\n",
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.test = test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N09BmOZOUHIr"
      },
      "source": [
        "Con el entendimiento de la función `WindowGenerator` vamos a realizar nuestro ejercicio de codigo, que consiste en forzar `WindowGenerator` para que siempre genere una \"ventana\" para un problema `many-to-one`. \n",
        "1. Lo unico que vamos a variar son las muestras pasadas/lags que usaremos para definir la ventana.\n",
        "2. Dentro de la función se sugiere ya la partición entre el conjunto de entrenamiento y prueba. Observa lo siguiente:\n",
        "    1. En este tipo de problemas una partición aleatoria no es una opción por que el orden es importante.\n",
        "    2. Dentro de la función se usa una partición 80%-20%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zfk-zyGdUHIs"
      },
      "outputs": [],
      "source": [
        "#ejercicio de codigo\n",
        "def many_to_one_custom(dataset, look_back=1):\n",
        "    \"\"\"Funcion que forza `WindowGenerator`\n",
        "    \n",
        "    dataset: matriz numpy con el conjunto de datos\n",
        "    look_back: numero de retrasos con los cuales queremos construir\n",
        "        las caracteristicas\n",
        "    \n",
        "    Retorna:\n",
        "      un numpy array con los valores de X (debe ser una matrix)\n",
        "      un numpy array con los valores de Y \n",
        "        (debe ser un vector columna, el # de renglones debe ser igual de renglones del numpy de X)\n",
        "\n",
        "    \"\"\"\n",
        "    n = len(dataset)\n",
        "    # Las primeras muestras hasta completar el 80%.\n",
        "    train_df = dataset[0:int(n*0.8)]\n",
        "    # Las siguientes muestras luego del 80% hasta llegar al final.\n",
        "    test_df = dataset[int(n*0.8):]\n",
        "    # Reemplazar por los valores correctos\n",
        "    ventana =  WindowGenerator(train_df ... , \n",
        "                               test_df = ... ,\n",
        "                               input_width=..., \n",
        "                               label_width=..., \n",
        "                               shift=1)   \n",
        "    return ventana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KLTMOfNsv9u"
      },
      "outputs": [],
      "source": [
        "GRADER.run_test(\"ejercicio1\", many_to_one_custom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJqFszd27d3c"
      },
      "outputs": [],
      "source": [
        "# observemos el funcionamiento de nuestra funcion.\n",
        "# Reemplaza los valores para observar el funcionamiento\n",
        "window =  many_to_one_custom(df, 2)\n",
        "print(window)\n",
        "window.split_window(with_example=True)\n",
        "window.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7mgNk-WUHIu"
      },
      "source": [
        "## Ejercicio 2 - Experimentar con RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbk27o_vUHIu"
      },
      "source": [
        "En el siguiente ejercicio vamos a crear una función para construir una RNN usando la libreria ya mencioanda.  \n",
        "\n",
        "1. Asignar como funcion de perdida el valor del error medio absoluto.\n",
        "2. Usar solo los objetos importados al inicio de la celda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB-t3-IosUtZ"
      },
      "outputs": [],
      "source": [
        "# ejercicio de código \n",
        "# usar solo estos objetos\n",
        "# importados\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def create_rnn_model(look_back, num_hidden_neurons):\n",
        "    \"\"\"funcion que crear modelo que usa mean_absolute_error\n",
        "    como funcion de perdida\n",
        "    RNN con base al número de lags y numero de neuronas\n",
        "\n",
        "    parametros\n",
        "      look_back (int): numero de retrasos a ejecutar\n",
        "      num_hidden_neurons (int): numero neuronas en la capa oculta\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "    # Se inicializa el modelo\n",
        "    # Podemos asignar un nombre\n",
        "    model = Sequential(name='rnn')\n",
        "    # Adicionar una capa RNN\n",
        "    # Reemplazar los valores\n",
        "    # Asigna el nombre de rnn_layer\n",
        "    rnn_layer = SimpleRNN(num_hidden_neurons, input_shape = (..., ...),  use_bias=True, name = ...) \n",
        "    # En tensorflow debemos adicionar la capa \n",
        "    # al modelo.\n",
        "    model.add(rnn_layer)\n",
        "    # La red termina con una capa Densa de una salida.\n",
        "    model.add(Dense(1, name = \"dense_layer\"))\n",
        "    # reemplazar la perdida por el parametro correcto.\n",
        "    # dejar el optimizador `adam`\n",
        "    model.build()\n",
        "    model.compile(loss=..., optimizer='adam')\n",
        "    return(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKvxqANBv4yI"
      },
      "outputs": [],
      "source": [
        "GRADER.run_test(\"ejercicio2\", create_rnn_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePqqC9GYLp4f"
      },
      "outputs": [],
      "source": [
        "rnn = create_rnn_model(look_back = 1,num_hidden_neurons = 2) \n",
        "rnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZ7EgKtULp4f"
      },
      "outputs": [],
      "source": [
        "rnn = create_rnn_model(look_back = 2,num_hidden_neurons = 4) \n",
        "rnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6Kh9E3J-4-f"
      },
      "source": [
        "Con nuestra funcion que crea modelos, vamos experimentar variando los dos parametros:\n",
        "\n",
        "- número de retrasos\n",
        "- número de neuronas en la capa oculta\n",
        "\n",
        "Otras condiciones: \n",
        "- Vamos a dejar fijo el # de epocas 25.\n",
        "- Usaremos la metrica de error absoluto medio. Recordar que solo usamos la implementación de [sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
        "- usar la función para crear la ventana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR2X2aHeUHIu"
      },
      "outputs": [],
      "source": [
        "# Ejercicio de código\n",
        "def experimentar_rnn(data, look_backs, hidden_neurons):\n",
        "    \"\"\"funcion que realiza experimentos para evaluar una RNN de elman usando\n",
        "        el error absoluto medio como medida de error\n",
        "    \n",
        "    data: pd.Dataframe, dataset a usar\n",
        "    look_back: List[int], lista con los numero de retrasos a evaluar\n",
        "    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta\n",
        "    retorna:\n",
        "        pd.Dataframe\n",
        "    \"\"\"\n",
        "    # Normalizar usando min_max scaler.\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    normalized_df = data.copy()\n",
        "    normalized_df[plot_cols] = scaler.fit_transform(data)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for num_hidden_neurons in hidden_neurons:\n",
        "        for look_back in look_backs:\n",
        "            # aplicar la transformacion.\n",
        "            window =  ... (normalized_df, look_back)\n",
        "            model = create_rnn_model(look_back = look_back, num_hidden_neurons = num_hidden_neurons)\n",
        "            MAX_EPOCHS =...\n",
        "            model.fit(x = ... , epochs=MAX_EPOCHS,  verbose = 0)\n",
        "            # predecimos en los conjuntos\n",
        "            trainYPred  = model.predict(x=...)\n",
        "            testYPred = model.predict(...)\n",
        "            # se debe restringir el valor real.\n",
        "            errorPrueba =  ...(y_true = window.test_df.head(testYPred.shape[0]), \n",
        "                                               y_pred = ...)\n",
        "             # se debe restringir el valor real.\n",
        "            errorEntrenamiento =  ...(y_true = window.train_df.head(trainYPred.shape[0]), \n",
        "                                                      y_pred= ... )\n",
        "            resultados.loc[idx,'lags'] = ...\n",
        "            resultados.loc[idx,'neuronas por capa'] = ...\n",
        "            resultados.loc[idx,'Métrica rendimiento en entrenamiento'] = ...\n",
        "            resultados.loc[idx,'Métrica de rendimiento prueba'] = ...\n",
        "            idx+=1\n",
        "            print(\"termina para\", look_back, num_hidden_neurons)\n",
        "    \n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffJwb8WXUHIw"
      },
      "outputs": [],
      "source": [
        "GRADER.run_test(\"ejercicio3\", experimentar_rnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p72IA8WCUHIy"
      },
      "source": [
        "Ahora vamos a ver los resultados del experimentos:\n",
        "\n",
        "1. variando los lags dejando las neuronas por capa fijas\n",
        "2. variando las neuronas y dejando los retrasos fijos\n",
        "\n",
        "experimente con diferentes configuraciones. Por la inicialización aleatorias los resultados pueden cambiar. Preste a los patrones que se van presentando y no a los valores exactos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOaV_Hn7UHIz"
      },
      "outputs": [],
      "source": [
        "# observa el comportamiento de los lags\n",
        "resultadosRNN = experimentar_rnn(df, look_backs = [1,6,12,24], hidden_neurons=[15])\n",
        "# plot\n",
        "ax1  = sns.relplot(data = resultadosRNN, x = 'lags', y = 'Métrica de rendimiento prueba', kind = 'line', aspect = 2)\n",
        "ax1.fig.suptitle('efecto del # retrasos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqHNlGOBUHI2"
      },
      "outputs": [],
      "source": [
        "resultadosRNN = experimentar_rnn(df, look_backs = [24], hidden_neurons=[1,2,4,16])\n",
        "ax2  = sns.relplot(data= resultadosRNN, x= 'neuronas por capa', y = 'Métrica de rendimiento prueba', kind = 'line', aspect = 2)\n",
        "ax2.fig.suptitle('efecto del # neuronas')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tSw9j936UHI4"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Por qué seguir aumentando los tiempos de retardo no implica siempre una mejora en la predicción del modelo?\n",
        "respuesta_3 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aZorFYfuLp4g"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Explique la principal diferencia entre un MLP y una red recurrente??\n",
        "#@markdown ¿Cual de las opciones está mejor justificada?\n",
        " \n",
        "#@markdown A) En un MLP no existe información compartida a través de las capas ocultas. En las RNN la capa de estado retro-alimenta las salidas previas ayudando a modelar problemas donde el orden en la secuencia es importante.\n",
        " \n",
        "#@markdown B) En un MLP es posible mediante la capa oculta simula una capa de estao. En las RNN la capa de estado NO debe ser simula, esto ayuda a modelar problemas donde el orden en la secuencia es importante.\n",
        " \n",
        "#@markdown C) El MLP y las RNN son equivalentes, solo que las RNN se entrenan usando Backpropagation through time (BPTT). Esto ayuda a modelar problemas donde el orden en la secuencia es importante.\n",
        " \n",
        "#@markdown D) Las RNN se entrenan usando Backpropagation through time (BPTT), esto ayuda a modelar problemas donde el orden en la secuencia es importante. Un MLP no puede ser entrenado mediante BPTT.\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_4 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUBn1aHoUHJE"
      },
      "source": [
        "## Ejercicio 3 - Comparación con LSTM\n",
        "\n",
        "En nuestro ultimo ejercicio, vamos a comparar los resultados obtenidos hasta ahora con una LSTM. Para ellos vamos a usar volver a usar [Tensorflow](https://www.tensorflow.org/?hl=es-419).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kXqnWgG1UHJF"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿por qué una red LSTM puede ser más adecuada para resolver este problema? justifique\n",
        "respuesta_5 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NeZ5PiEUHJG"
      },
      "source": [
        "Aca creamos el modelo LSTM usando tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fns_PiMPUHJG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "def create_lstm_model(look_back, num_hidden_neurons):\n",
        "    \"\"\"funcion que crear modelo LSTM con base al número de lags y numero de neuronas\"\"\"\n",
        "    model = Sequential(name='lstm')\n",
        "    model.add(LSTM(num_hidden_neurons, input_shape=(look_back, 1)))\n",
        "    model.add(Dense(1))\n",
        "    model.build()\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px5VQBhDUHJI"
      },
      "source": [
        "Vamos aseguranos de completar el código para lograr:\n",
        "-  Epocas = 50\n",
        "-  Pasar los parametros el la función `create_lstm_model`\n",
        "- Usaremos la metrica de error absoluto medio. Recordar que solo usamos la implementación de [sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
        "- usar la función para crear la ventana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-zgWDvfUHJI"
      },
      "outputs": [],
      "source": [
        "# Ejercicio de código\n",
        "def experimentar_LSTM(data, look_backs, hidden_neurons):\n",
        "    \"\"\"funcion que realiza experimentos para evaluar LSTM usando\n",
        "        el error absoluto medio como medida de error\n",
        "    \n",
        "    data: pd.Dataframe, dataset a usar\n",
        "    look_back: List[int], lista con los numero de retrasos a evaluar\n",
        "    hidden_neurons: List[int], list con el numero de neuronas en la capa oculta\n",
        "    retorna: \n",
        "        pd.Dataframe\n",
        "    \"\"\"\n",
        "    # Normalizar usando min_max scaler.\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    normalized_df = data.copy()\n",
        "    normalized_df[plot_cols] = scaler.fit_transform(data)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for num_hidden_neurons in hidden_neurons:\n",
        "        for look_back in look_backs:\n",
        "            # aplicar la transformacion.\n",
        "            window =  ... (normalized_df, look_back)\n",
        "            model = ... (look_back = look_back, num_hidden_neurons = num_hidden_neurons)\n",
        "            # entrenemos el modelo.\n",
        "            MAX_EPOCHS = 40\n",
        "            model.fit(x = ... , epochs=MAX_EPOCHS,  verbose = 0)\n",
        "            # predecimos en los conjuntos\n",
        "            trainYPred  = model.predict(...)\n",
        "            testYPred = model.predict(...)\n",
        "            # se debe restringir el valor real.\n",
        "            errorPrueba =  ...(y_true = window.test_df.head(testYPred.shape[0]), \n",
        "                                               y_pred=...)\n",
        "             # se debe restringir el valor real.\n",
        "            errorEntrenamiento =  ...(y_true = window.train_df.head(trainYPred.shape[0]), \n",
        "                                                      y_pred= ...)\n",
        "            resultados.loc[idx,'lags'] = ...\n",
        "            resultados.loc[idx,'neuronas por capa'] = ...\n",
        "            resultados.loc[idx,'Métrica rendimiento en entrenamiento'] = ...\n",
        "            resultados.loc[idx,'Métrica de rendimiento prueba'] = ...\n",
        "            idx+=1\n",
        "            print(\"termina para\", look_back, num_hidden_neurons)\n",
        "    \n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KOxj5zIUHJK"
      },
      "outputs": [],
      "source": [
        "# ignorar los prints!\n",
        "GRADER.run_test(\"ejercicio4\", experimentar_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mt8kaTCUHJL"
      },
      "outputs": [],
      "source": [
        "# demora algunos minutos!\n",
        "resultadosLSTM = experimentar_LSTM(df, [1,6,12,24], hidden_neurons=[4,8,16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_md7Qc_UHJN"
      },
      "outputs": [],
      "source": [
        "# para ver los resultados\n",
        "# en esta instruccion se va resaltar el mejor\n",
        "# error y tiempo de entrenamiento\n",
        "resultadosLSTM.style.highlight_min(color = 'green', axis = 0, subset = ['Métrica de rendimiento prueba'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrKvqWw2UHJS"
      },
      "outputs": [],
      "source": [
        "GRADER.check_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bqLnLhkbUHJT"
      },
      "outputs": [],
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ks-ybfUHJV"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJl4We7lUHJV"
      },
      "outputs": [],
      "source": [
        "GRADER.grade()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lab5_parte1 copy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('udea')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c216c800eb90efed5b4e7fbe9fb3a04a2ffbc3fe33e223430d52baede0ec7928"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
