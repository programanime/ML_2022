{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1tb9xQfodtj"
      },
      "source": [
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2022-07-24 18:45:40--  https://raw.githubusercontent.com/mariabda2/ML_2022/master/Labs/commons/utils/general.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15337 (15K) [text/plain]\n",
            "Saving to: ‘general.py’\n",
            "\n",
            "     0K .......... ....                                       100% 10.7M=0.001s\n",
            "\n",
            "2022-07-24 18:45:41 (10.7 MB/s) - ‘general.py’ saved [15337/15337]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lab configuration started\n",
            "installing libraries\n",
            "Collecting gspread\n",
            "  Downloading gspread-5.4.0-py3-none-any.whl (37 kB)\n",
            "Collecting google-auth>=1.12.0\n",
            "  Downloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
            "Collecting google-auth-oauthlib>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.5.2-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/german/venv/udea/lib/python3.8/site-packages (from google-auth>=1.12.0->gspread) (1.16.0)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting pyasn1>=0.1.3\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in /home/german/venv/udea/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.28.1)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/german/venv/udea/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/german/venv/udea/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/german/venv/udea/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/german/venv/udea/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (1.26.10)\n",
            "Installing collected packages: cachetools, pyasn1, rsa, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, gspread\n",
            "Successfully installed cachetools-5.2.0 google-auth-2.9.1 google-auth-oauthlib-0.5.2 gspread-5.4.0 oauthlib-3.2.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sh: 1: cannot open 3.3.1: No such file\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==1.01\n",
            "  Using cached scikit_learn-1.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /home/german/venv/udea/lib/python3.8/site-packages (from scikit-learn==1.01) (1.8.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /home/german/venv/udea/lib/python3.8/site-packages (from scikit-learn==1.01) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/german/venv/udea/lib/python3.8/site-packages (from scikit-learn==1.01) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /home/german/venv/udea/lib/python3.8/site-packages (from scikit-learn==1.01) (1.23.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.1.1\n",
            "    Uninstalling scikit-learn-1.1.1:\n",
            "      Successfully uninstalled scikit-learn-1.1.1\n",
            "Successfully installed scikit-learn-1.1.0\n",
            "downloading files\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2022-07-24 18:45:50--  https://raw.githubusercontent.com/mariabda2/ML_2022/master/Labs/commons/utils/data/AirQuality.data\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 567677 (554K) [text/plain]\n",
            "Saving to: ‘AirQuality.data’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  9% 3.47M 0s\n",
            "    50K .......... .......... .......... .......... .......... 18% 3.77M 0s\n",
            "   100K .......... .......... .......... .......... .......... 27% 8.93M 0s\n",
            "   150K .......... .......... .......... .......... .......... 36% 3.52M 0s\n",
            "   200K .......... .......... .......... .......... .......... 45% 9.60M 0s\n",
            "   250K .......... .......... .......... .......... .......... 54% 3.56M 0s\n",
            "   300K .......... .......... .......... .......... .......... 63% 6.16M 0s\n",
            "   350K .......... .......... .......... .......... .......... 72% 1.87M 0s\n",
            "   400K .......... .......... .......... .......... .......... 81% 6.53M 0s\n",
            "   450K .......... .......... .......... .......... .......... 90% 8.63M 0s\n",
            "   500K .......... .......... .......... .......... .......... 99% 2.01M 0s\n",
            "   550K ....                                                  100% 27.8M=0.1s\n",
            "\n",
            "2022-07-24 18:45:51 (3.96 MB/s) - ‘AirQuality.data’ saved [567677/567677]\n",
            "\n",
            "--2022-07-24 18:45:51--  https://raw.githubusercontent.com/mariabda2/ML_2022/master/Labs/commons/utils/lab4.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11240 (11K) [text/plain]\n",
            "Saving to: ‘lab4.py’\n",
            "\n",
            "     0K ..........                                            100% 15.7M=0.001s\n",
            "\n",
            "2022-07-24 18:45:51 (15.7 MB/s) - ‘lab4.py’ saved [11240/11240]\n",
            "\n",
            "--2022-07-24 18:45:51--  https://raw.githubusercontent.com/mariabda2/ML_2022/master/Labs/commons/utils/imports.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 556 [text/plain]\n",
            "Saving to: ‘imports.py’\n",
            "\n",
            "     0K                                                       100% 26.9M=0s\n",
            "\n",
            "2022-07-24 18:45:51 (26.9 MB/s) - ‘imports.py’ saved [556/556]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lab configured\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'sns' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/german/repos/ML_2022/Labs/lab4/lab4_parte1.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/german/repos/ML_2022/Labs/lab4/lab4_parte1.ipynb#ch0000001vscode-remote?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlab4\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/german/repos/ML_2022/Labs/lab4/lab4_parte1.ipynb#ch0000001vscode-remote?line=15'>16</a>\u001b[0m GRADER \u001b[39m=\u001b[39m part_1()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/german/repos/ML_2022/Labs/lab4/lab4_parte1.ipynb#ch0000001vscode-remote?line=16'>17</a>\u001b[0m sns\u001b[39m.\u001b[39mset_context(\u001b[39m'\u001b[39m\u001b[39mtalk\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
          ]
        }
      ],
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "in_colab = True\n",
        "import os\n",
        "\n",
        "if not in_colab:\n",
        "    import sys ; sys.path.append('../commons/utils/');\n",
        "else: \n",
        "    os.system('wget https://raw.githubusercontent.com/mariabda2/ML_2022/master/Labs/commons/utils/general.py -O general.py')\n",
        "    from general import configure_lab4\n",
        "    configure_lab4()\n",
        "from lab4 import *\n",
        "\n",
        "GRADER = part_1()\n",
        "sns.set_context('talk')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEFZ1bNsodtm"
      },
      "source": [
        "# Laboratorio 4 - Parte 1. Redes neuronales - perceptrón multicapa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIyPCtR3odtm"
      },
      "source": [
        "Este ejercicio tiene como objetivo implementar una red neuronal artificial de tipo perceptrón multicapa (MLP) para resolver un problema de regresión. Usaremos la librería sklearn. Consulte todo lo relacionado con la definición de hiperparámetros, los métodos para el entrenamiento y la predicción de nuevas muestras en el siguiente enlace: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAVPFqINodtn"
      },
      "source": [
        "Para este ejercicio usaremos la base de datos sobre calidad del aire, que ha sido usada en laboratorios previos, pero en este caso trataremos de predecir dos variables en lugar de una, es decir, abordaremos **un problema de múltiples salidas**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1ILV7RModtn"
      },
      "outputs": [],
      "source": [
        "#cargamos la bd que está en un archivo .data y ahora la podemos manejar de forma matricial\n",
        "if in_colab:\n",
        "    db = np.loadtxt('AirQuality.data',delimiter='\\t')\n",
        "else:\n",
        "    db = np.loadtxt('../commons/utils/data/AirQuality.data',delimiter='\\t') \n",
        "\n",
        "#Esta es la base de datos AirQuality del UCI Machine Learning Repository. En la siguiente URL se encuentra toda\n",
        "#la descripción de la base de datos y la contextualización del problema.\n",
        "#https://archive.ics.uci.edu/ml/datasets/Air+Quality#\n",
        "\n",
        "x = db[:,0:11]\n",
        "y = db[:,11:13]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKlFuQyRodtp"
      },
      "source": [
        "Para calcular los errores, vamos a explorar y usar el [modulo de metricas den sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
        "\n",
        "Podemos observar que el modulo tiene metricas para regresión y clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFIUq69Modtp"
      },
      "source": [
        "## Ejercicio 1 - Experimentar con MLP para regresión\n",
        "\n",
        "Para porder implementar nuestra función, lo primero que debemos entender la estrucutra de la red. \n",
        "\n",
        "Como mencionamos, vamos a solucionar un problema de multiples salidas. Estas salidas con valores continuos. Por lo tanto debemos garantizar que la capa de salida de nuestra red tenga la capacidad de modelar este tipo de datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xjF6liTmodtp"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿De acuerdo al problema planteado, que función de activación debe usar el MLP para un problema de regresión?\n",
        "respuesta_1 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G_bSsYcodtr"
      },
      "source": [
        "Una característica de los modelos de sklearn, es que ciertos tipos de atributos, sólo pueden ser accedidos cuanto se entrena el modelo, explora las siguiente celdas de código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0ybj-1vodtv"
      },
      "outputs": [],
      "source": [
        "mlp = MLPRegressor()\n",
        "xrandom = np.random.rand(10,2)\n",
        "yrandom = np.zeros(10)\n",
        "mlp.fit(X=xrandom, y=yrandom)\n",
        "print(mlp.activation)\n",
        "print(mlp.out_activation_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp = MLPRegressor(activation='logistic')\n",
        "xrandom = np.random.rand(10,2)\n",
        "yrandom = np.zeros(10)\n",
        "mlp.fit(X=xrandom, y=yrandom)\n",
        "print(mlp.activation)\n",
        "print(mlp.out_activation_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cual es la diferencia entre las dos funciones de activación?\n",
        "#@markdown ¿Cual de las opciones está mejor justificada?\n",
        " \n",
        "#@markdown A) `identity` es una función lineal y parte de la capa de entrada. El parámetro `activation` configura la capa de salida.\n",
        " \n",
        "#@markdown B) `identity` es una representación de no tener función activación es parte de la capa de entrada. El parámetro `activation` configura la función de activación de capa de salida.\n",
        " \n",
        "#@markdown C)`identity` es una representación de no tener función activación es parte de la capa de salida.  El parámetro `activation` configura la función de activación de las capas ocultas.\n",
        " \n",
        "#@markdown D) `identity` es una representación de no tener función activación es parte de la capa oculta.  El parámetro `activation` configura la función de activación de la capa de salida.\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_2 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udcddNBiodtz"
      },
      "source": [
        "Una vez entendido como sklearn usa las funciones de activación, vamos a crear la función para realizar los experimentos.\n",
        " \n",
        "Vamos a completar la función con el código necesario para usar una red neuronal tipo MLP para solucionar el problema de regresión propuesto.\n",
        "1. Como función de activación en las capas ocultas use la función 'tanh'.\n",
        "2. Ajuste el número máximo de épocas a 300.\n",
        "3. Dejamos como variables el número de capas ocultas y el número de neuronas por capa.\n",
        "5. debemos seleccionar la función adecuada del [modulo de sklearn para calcular el Error Porcentual Absoluto Medio (MAPE en sigla en ingles)](https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics). Tener en cuenta qué parámetros usar.\n",
        "6. Debemos usar los nombres explícitos, por ejemplo si para el MLP es necesario usar el parámetro `activation`, debe ser llamado: `MLPRegressor(activation=...)`\n",
        "7. Explorar qué hace la siguiente linea de codigo `tuple(2*[100])`\n",
        " \n",
        "**NOTA**: observe el  parámetro `random_state=1` por favor conservarlo, ya que esto hace que los resultados sean similares a lo largo de las ejecuciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-SdZ9H_odt0"
      },
      "outputs": [],
      "source": [
        "# ejercicio de código\n",
        "\n",
        "def experimetar_mlp(num_hidden_layers, num_neurons, X,Y):\n",
        "    \"\"\" función para realizar experimentos con el MLP\n",
        "    x: matriz de numpy con caracteristicas\n",
        "    y: vector numpy con las variables a predecir\n",
        "    num_hidden_layers: list de enteros con el numero de capdas\n",
        "        ocultas a usar\n",
        "    num_neurons: list de enteros con el numero de neuronas a usar\n",
        "    \n",
        "    Retorna: dataframe con 6 columnas:\n",
        "        - numero de capas, numero de neuronas\n",
        "        - promedio de error prueba variable 1 y desviación estandar\n",
        "        - promedio de error prueba variable 2 y desviación estandar\n",
        "        \n",
        "    \"\"\"\n",
        "    #Validamos el modelo\n",
        "    Folds = 3\n",
        "    ss = ShuffleSplit(n_splits=Folds, test_size=0.2, random_state = 1)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for hidden_layers in num_hidden_layers:\n",
        "        for neurons in num_neurons:\n",
        "            for j, (train, test) in enumerate(ss.split(X)):\n",
        "                # para almacenar errores intermedios\n",
        "                ErrorY1 = np.zeros(Folds)\n",
        "                ErrorY2 = np.zeros(Folds)\n",
        "                Xtrain= X[train,:]\n",
        "                Ytrain = Y[train,:]\n",
        "                Xtest = X[test,:]\n",
        "                Ytest = Y[test,:]\n",
        "                #Normalizamos los datos\n",
        "                scaler = StandardScaler().fit(...)       \n",
        "                Xtrain = scaler.transform(...)\n",
        "                Xtest = scaler.transform(...)\n",
        "                #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "                # prestar atención a los parametros, correctos.\n",
        "                hidden_layer_sizes = tuple(...)\n",
        "                mlp = MLPRegressor(..., random_state=1)\n",
        "                mlp...(....)\n",
        "                #Use para el modelo para hacer predicciones sobre el conjunto Xtest\n",
        "                Yest = mlp...(...)\n",
        "                #Mida el error absoluto medio para cada una de las dos salidas\n",
        "                #Observe bien la documentación. recordar que esta resolviendo\n",
        "                #un problema de multiples salidas\n",
        "                errors = ....(y_true=..., y_pred = ..., multioutput=...)\n",
        "                ErrorY1[j] = errors[0]\n",
        "                ErrorY2[j] = errors[1]\n",
        "        \n",
        "            print('error para salida 1 = ' + str(np.mean(ErrorY1)) + '+-' + str(np.std(ErrorY1)))\n",
        "            print('error para 2 = ' + str(np.mean(ErrorY2)) + '+-' + str(np.std(ErrorY2)))\n",
        "        \n",
        "            resultados.loc[idx,'capas ocultas'] = hidden_layers\n",
        "            resultados.loc[idx,'neuronas en capas ocultas'] = neurons \n",
        "            resultados.loc[idx,'error de prueba y1(media)'] = ...(ErrorY1)\n",
        "            resultados.loc[idx,'intervalo de confianza y1'] = ...(ErrorY1)\n",
        "            resultados.loc[idx,'error de prueba y2(media)'] = ...(ErrorY2)\n",
        "            resultados.loc[idx,'intervalo de confianza y2'] = ...(ErrorY2)\n",
        "            idx+=1\n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBVxxl25odt1"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "# ignorar los prints\n",
        "GRADER.run_test(\"ejercicio1\", experimetar_mlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXCQp7oJw9gd"
      },
      "source": [
        "vamos a realizar los experimentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV-ka-ukodt3"
      },
      "outputs": [],
      "source": [
        "# tarda unos minutos!!\n",
        "resultados_mlpr = experimetar_mlp(num_hidden_layers = [1,2,3], num_neurons  = [8,12,16], X=x, Y=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7insQmbOodt5"
      },
      "outputs": [],
      "source": [
        "sns.relplot(data = resultados_mlpr,  x='neuronas en capas ocultas', y = 'error de prueba y1(media)', style= 'capas ocultas', kind = 'line')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CpSvl_I4odt7"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown Con base a los reusltados, ¿podriamos saber a priori los mejores parametros (capas ocultas, # de neuronas), que tan correcto es asumir patrones en los valores de los parametros?\n",
        "respuesta_3 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4y1IDLzsw9ge"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cual es el rol de random_state en la función `MLPRegressor`?\n",
        "#@markdown ¿Cual de las opciones está mejor justificada?\n",
        " \n",
        "#@markdown A) Usando los valores por defecto, determina la inicialización de los pesos de cada una de las neuronas en cada capa del perceptrón.\n",
        " \n",
        "#@markdown B) Sin importar los otros valores, determina SOLO la inicialización de los pesos de cada una de las neuronas en cada capa del perceptrón.\n",
        " \n",
        "#@markdown C) Determina la inicialización y las funciones de activación de los pesos de cada una de las neuronas en cada capa del perceptrón.\n",
        " \n",
        " #@markdown D) Usando los valores por defecto, determina la inicialización de los pesos de la capa de salida del perceptrón.\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_4 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY2yg06Nodt8"
      },
      "source": [
        "## Ejercicio 2 Experimentar con MLP para clasificación\n",
        "\n",
        "A continuación se leen los datos de un problema de clasificación. El problema corresponde a la clasifiación de dígitos escritos a mano. Usaremos únicamente 4 de las 10 clases disponibles. Los datos fueron preprocesados para reducir el número de características. La técnica usada será analizada más adelante en el curso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQQrTIcZodt9"
      },
      "outputs": [],
      "source": [
        "digits = load_digits(n_class=4)\n",
        "#--------- preprocesamiento--------------------\n",
        "pca = PCA(0.99, whiten=True)\n",
        "data = pca.fit_transform(digits.data)\n",
        "#---------- Datos a usar ----------------------\n",
        "Xd = data\n",
        "Yd = digits.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AAZkhxDjodt_"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿Qué tipo de función de activación usa el modelo en la capa de salida para un problema de clasificación?\n",
        "respuesta_5 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6VwPK9RoduA"
      },
      "source": [
        "como lo hicmos antes, vamos a comprobar con la libreria la función de activación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10TRJf1SoduB"
      },
      "outputs": [],
      "source": [
        "# ejercicio de código\n",
        "def output_activation_MPC():\n",
        "    \"\"\"funcion que entrena un modelo\n",
        "    con data aleatoria para confirmar la funcion\n",
        "    de activacion de la ultima capa\n",
        "    \"\"\"\n",
        "    mlp = ...()\n",
        "    # fit with some random data\n",
        "    xrandom = np.random.rand(10,2)\n",
        "    yrandom = np.zeros(10)\n",
        "    # llamar el metodo adecuado para entrenar\n",
        "    # el mlp con los x y 'y' random\n",
        "    mlp.fit(...)\n",
        "    # retornar el atributo de mlp adecuado\n",
        "    return (...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio2\", output_activation_MPC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR1AWh6doduE"
      },
      "outputs": [],
      "source": [
        "print(\"la función de activación para un problema de clasificación es:\", output_activation_MPC())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUrb8sX1oduG"
      },
      "source": [
        "Ahora en nuestro siguiente ejercicio vamos a implementar una red neuronal artificial de tipo perceptrón multicapa (MLP) para resolver un problema de clasificación. Usaremos la librería sklearn. Consulte todo lo relacionado con la definición de hiperparámetros, los métodos para el entrenamiento y la predicción de nuevas muestras en el siguiente enlace: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPXRYrtnoduG"
      },
      "source": [
        "\n",
        "Vamos completar la función con el código necesario para usar una red neuronal tipo MLP para solucionar el problema de clasificación propuesto.\n",
        "1. Como función de activación en las capas ocultas use la función tangencial hiperbólica. \n",
        "2. Ajuste el número máximo de épocas a 350.\n",
        "3. Dejamos como variables el número de capas ocultas y el número de neuronas por capa\n",
        "5. Seleccione la función adecuada del [modulo de sklearn para calcular la exactitud del clasificador](https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics). Tener en cuenta que parametros usar.\n",
        "6. Debemos usar los nombres explicitos, por ejemplo si para el MLP es necesario usar el parametro `activation`, debe ser llamado: `MLPClassifier(activation=...)`\n",
        "\n",
        "**NOTA**: cuando observe el el parametro `random_state=1` por favor conservarlo, ya que esto hace que los resultados sean similares a lo largo de las ejecucciones. *tener en cuenta esta observación para una de las preguntas abiertas que encuentras mas adelante del laboratorio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO3RLo4JoduG"
      },
      "outputs": [],
      "source": [
        "# ejercicio de código\n",
        "def experimetar_mlpc(X,Y, num_hidden_layers, num_neurons):\n",
        "    \"\"\" función para realizar experimentos con el MLP\n",
        "    x: matriz de numpy con caracteristicas\n",
        "    y: vector numpy con las variables a predecir\n",
        "    num_hidden_layers: list de enteros con el numero de capdas\n",
        "        ocultas a usar\n",
        "    num_neurons: list de enteros con el numero de neuronas a usar\n",
        "    \n",
        "    Retorna: dataframe con 4 columnas:\n",
        "        - numero de capas, numero de neuronas\n",
        "        - promedio de error prueba (exactitud/eficiencia) de claisficacion y desviación estandar        \n",
        "    \"\"\"\n",
        "    #Validamos el modelo\n",
        "    Folds = 3\n",
        "    skf = StratifiedKFold(n_splits=Folds)\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for hidden_layers in num_hidden_layers:\n",
        "        for neurons in num_neurons:\n",
        "            for j, (train, test) in enumerate(skf.split(..., ...)):\n",
        "                # para almacenar errores intermedios\n",
        "                Error = np.zeros(Folds)\n",
        "                Xtrain= X[train,:]\n",
        "                Ytrain = Y[train]\n",
        "                Xtest = X[test, :]\n",
        "                Ytest = Y[test]\n",
        "                #Normalizamos los datos\n",
        "                scaler = StandardScaler().fit(Xtrain)       \n",
        "                Xtrain = scaler.transform(Xtrain)\n",
        "                Xtest = scaler.transform(Xtest)\n",
        "                #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "                # prestar atención a los parametros, correctos.\n",
        "                hidden_layer_sizes = tuple(hidden_layers*[neurons])\n",
        "                mlp = MLPClassifier(..., random_state = 1)\n",
        "                # entrenar el MLP\n",
        "                ..fit(....)\n",
        "                #Use para el modelo para hacer predicciones sobre el conjunto Xtest\n",
        "                Yest = ...predict(...)\n",
        "                # recordar usar la medida adecuada de acuerdo a las instrucciones\n",
        "                Error[j] = ...(y_true = ...,  y_pred =...)\n",
        "                \n",
        "        \n",
        "            print('error para configuracion de params = ' + str(np.mean(Error)) + '+-' + str(np.std(Error)))\n",
        "        \n",
        "            resultados.loc[idx,'capas ocultas'] = hidden_layers\n",
        "            resultados.loc[idx,'neuronas en capas ocultas'] = neurons \n",
        "            resultados.loc[idx,'error de prueba(media)'] = np.mean(Error)\n",
        "            resultados.loc[idx,'intervalo de confianza'] = np.std(Error)\n",
        "            idx+=1\n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcMLaM4coduI"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio3\", experimetar_mlpc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCyR-W0RoduJ"
      },
      "outputs": [],
      "source": [
        "# tarda unos minutos!!\n",
        "resultados_mlpc = experimetar_mlpc(X = Xd, Y=Yd, num_hidden_layers=[1,2,3], num_neurons=[12,16,20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados_mlpc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FwrY7LFoduL"
      },
      "outputs": [],
      "source": [
        "# ver los resultados\n",
        "# notar como las capas ocultas y el # de neuronas influyen\n",
        "sns.relplot(data = resultados_mlpc,  x='neuronas en capas ocultas', y = 'error de prueba(media)', style= 'capas ocultas', kind = 'line')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IZJGmEnZoduO"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Cuántas neuronas en la capa de salida tiene el modelo? ¿Porqué debe tener ese número?\n",
        "respuesta_6 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "koqUM4gZw9gh"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown Llegas a una nueva compañía. En todos los proyectos observas que solo tienen perceptrones multicapa entrenados usado sklearn ¿que recomiendas?\n",
        "respuesta_7 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGfDfjGkoduP"
      },
      "source": [
        "**recordatorio** En la practica sklearn no es una la libreria indicada para desarollar redes neuronales, para practicas mas avanzadas y realizar modelos en el \"mundo real\" [se deben usar conceptos de deep learning y una libreria llamada Keras](https://colab.research.google.com/github/lexfridman/mit-deep-learning/blob/master/tutorial_deep_learning_basics/deep_learning_basics.ipynb). Adicional tener en cuenta [lo visto en teoria](https://mariabda2.github.io/ML_2022/clases/clase_14_Redes_Neuronales_Artificiales.html#desventajas-de-las-aproximaciones-clasicas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aRu5586oduP"
      },
      "outputs": [],
      "source": [
        "GRADER.check_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wL-i0zZyoduR"
      },
      "outputs": [],
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOcAojtRoduT"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M_nkZ_DoduT"
      },
      "outputs": [],
      "source": [
        "GRADER.grade()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab4_parte1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('udea')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c216c800eb90efed5b4e7fbe9fb3a04a2ffbc3fe33e223430d52baede0ec7928"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
