{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cww0rGZXTbDv"
      },
      "source": [
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras almacenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "in_colab = True\n",
        "import os\n",
        "\n",
        "if not in_colab:\n",
        "    import sys ; sys.path.append('../commons/utils/');\n",
        "else: \n",
        "    os.system('wget https://raw.githubusercontent.com/mariabda2/ML_2022/master/Labs/commons/utils/general.py -O general.py')\n",
        "    from general import configure_lab4\n",
        "    configure_lab4()\n",
        "from lab4 import *\n",
        "\n",
        "GRADER = part_2()\n",
        "sns.set_context('talk')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwRIzDC9TbD2"
      },
      "source": [
        "# Laboratorio 4 - Parte 2. Regularización de modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkLns0kiTbD3"
      },
      "source": [
        "En este laboratorio vamos analizar el efecto del sobre-ajuste (*over-fitting*), como identificarlo y como podemos regualizar los modelos para evitarlo o disminuir su efecto. \n",
        "\n",
        "En este laboratorio, vamos a enfocarnos en 2 modelos (usando libreria de sklearn): \n",
        "\n",
        "1. Regresión logistica \n",
        "2. MLP\n",
        "\n",
        "El sobre-ajuste tambien puede ser causado por la **maldición de la dimensionalidad**. **No vamos enfocarnos en como tratar esta condición** ya que esto lo vamos a ver un poco más adelante cuando evaluemos las tecnicas de selección de caracteristicas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBGpm893TbD3"
      },
      "source": [
        "Vamos usar [el dataset de calidad de vinos](https://archive.ics.uci.edu/ml/datasets/wine) para realizar nuestra practica. Vamos a convertir el problema a un problema de clasificación biclase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE2yg_cETbD3"
      },
      "outputs": [],
      "source": [
        "x,y = load_wine(return_X_y=True)\n",
        "unique, counts  = np.unique(y, return_counts=True)\n",
        "print(\"distribución original (claves las etiquetas, valores el número de muestras): \\n\", dict(zip(unique, counts )))\n",
        "y = np.where(y==0, 0, 1)\n",
        "unique, counts  = np.unique(y, return_counts=True)\n",
        "print(\"distribución luego de conversión (claves las etiquetas, valores el número de muestras): \\n\", dict(zip(unique, counts )))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYnk2FwSTbD5"
      },
      "source": [
        "Una de las condiciones para que se presenten sobre-ajustes es tener un conjunto de entrenamiento pequeño. \n",
        "\n",
        "En nuestra practica vamos a simular esta condición para ver que tecnicas podemos usar para reducir el efecto del sobre-ajuste. \n",
        "\n",
        "**Nota**\n",
        "1. En un problema real, si se observa que las medidas de rendimiento no satisfacen las necesidades, la respuesta puede ser que se necesiten más datos en el conjunto de entrenamiento. Las condiciones que usaremos en esta practica son para ver el efecto del sobre ajuste.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OQdVTAZTbD5"
      },
      "outputs": [],
      "source": [
        "# simular conjunto de datos pequeño\n",
        "x, x_test, y, y_test = train_test_split(x, y, test_size=0.6, random_state=10, stratify = y)\n",
        "scaler = StandardScaler().fit(x)\n",
        "x = scaler.transform(x)\n",
        "x_test = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap6L4HQwTbD7"
      },
      "source": [
        "## Ejercicio 1 - Detectar sobre ajuste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGta0nulTbD7"
      },
      "source": [
        "En nuestro primer ejercicio vamos a crear una función para detectar las diferencias entre los errores de entrenamiento y de prueba.\n",
        "1. Calcular el error de entrenamiento y prueba.\n",
        "2. La función recibe de manera arbitraria un estimador de sklearn.\n",
        "3. [Usar la exactitud balanceada como métrica de rendimiento](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html).\n",
        "4. Se debe retornar la diferencia absoluta (solo números positivos) entre entrenamiento y prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mggj15DfTbD8"
      },
      "outputs": [],
      "source": [
        "# ejercicio de código\n",
        "def diff_train_test(sklearnModel, Xtrain, Ytrain, Xtest, Ytest):\n",
        "    \"\"\"función que retorna error de entrenamiento\n",
        "    sklearnModel: objeto estimador de sklearn ya entrenado\n",
        "    Xtrain: matriz numpy con las caracteristicas de entrenaniento\n",
        "    Ytrain: matrix numpy con las etiquetas de entrenamiento\n",
        "    Xtest: matriz numpy con las caracteristicas de prueba\n",
        "    Ytest: matrix numpy con las etiquetas de prueba\n",
        "    \n",
        "    retorna: tupla con tres elementos:\n",
        "        error entrenamiento, error test y \n",
        "        diff absoluta entre error y test\n",
        "    \"\"\"\n",
        "    y_pred=sklearnModel...(Xtrain)\n",
        "    error_train = ...(...)\n",
        "    y_pred=sklearnModel...(Xtest)\n",
        "    error_test = ...(...)\n",
        "    diff = abs(...)\n",
        "    return (error_train, error_test, diff)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM6tpVKHTbD9"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio1\", diff_train_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿porque balanced_accuracy_score es una mejor medida de rendimiento en el contexto del problema?\n",
        "#@markdown ¿Cual de las opciones está mejor justificada?\n",
        " \n",
        "#@markdown A) Cualquier medida sería útil para determinar sobreentrenamiento, solo estamos explorando las posibilidades de la librería.\n",
        " \n",
        "#@markdown A) Nuestro problema es desbalanceado, balanced_accuracy_score es una medida útil en este contexto, por que balancea sensibilidad y la especificidad.\n",
        " \n",
        "#@markdown C) Nuestro problema es la clasificación de tres clases balanceadas, por lo tanto cualquier medida sería útil.\n",
        " \n",
        "#@markdown D) Nuestro problema es desbalanceado, balanced_accuracy_score es una medida útil en este contexto por que tiene en cuenta el recall por cada clase.\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_1 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUhxHnmzTbD_"
      },
      "source": [
        "Con la función construida, vamos a usarla para verificar la differencia entre el error de entrenamiento y prueba para los dos modelos que vamos a usar:\n",
        "1. MLP con dos capas, cada una con 64 neuornas. `random_state=1` es usado para lograr tener los mismos resultados siempre\n",
        "2. [Regresión logistica forzada para que no use ninguna regularización](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression). `random_state=1` es usado para lograr tener los mismos resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9gaJVOxTbEA"
      },
      "outputs": [],
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=[32,16], solver='sgd', max_iter=200, alpha = 1e-6, random_state=1)\n",
        "mlp.fit(X=x, y=y)\n",
        "# aca usamos el * para pasa cadar elemento como argumento \n",
        "print(\"MLP entrenamiento:{0:.3f}, test:{1:.3f} y diff {2:.3f}\".format(*diff_train_test(mlp, x,y, x_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qkKdVakTbEC"
      },
      "outputs": [],
      "source": [
        "reg = LogisticRegression(penalty='none', max_iter=200,  random_state=1)\n",
        "reg.fit(x, y)\n",
        "print(\"Logistic Regresion entrenamiento:{0:.3f}, test:{1:.3f} y diff {2:.3f}\".format(*diff_train_test(reg, x,y, x_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6t9dJ5ETbEE"
      },
      "source": [
        "## Ejercicio 2 - Experimentar con MLP regularizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZpv_cP-TbEE"
      },
      "source": [
        "Vamos a comenzar regularizar el modelo, el primer metodo que vamos a usar es el de parada anticipada (*early-stopping*). Este ya se encuentra implementado dentro de la libreria, vamos a experimentar con este parametro y el numero de neuronas en el MLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SkoSdxHfTbEE"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿Explique en sus palabras a que corresponde el método de parada anticipada?\n",
        "respuesta_2 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "77yPBEmjTbEG"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿basándose en la documentación de sklearn para MLPClassifier qué relación tiene el parámetro validation_fraction con la parada anticipada?\n",
        "respuesta_3 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBQr3xG_TbEI"
      },
      "outputs": [],
      "source": [
        "# ejercicio de código\n",
        "def exp_mlp_early_stop(num_neurons, is_early_stop, Xtrain,Xtest,Ytrain, Ytest):\n",
        "    \"\"\" función para realizar experimentos con el MLP con early stopping\n",
        "    num_neurons: list de enteros con el numero de neuronas a usar\n",
        "    is_early_stop: list de boolean para confirmar si se aplica early stop\n",
        "    Xtrain: matriz de numpy con caracteristicas de entrenamiento\n",
        "    Xtest: matriz de numpy con caracteristicas de prueba\n",
        "    ytrain: vector numpy con etiqueta de entrenamiento\n",
        "    ytest: vector numpy con etiqueta de prueba\n",
        "    \n",
        "    Retorna: dataframe con 5 columnas:\n",
        "        - numero de neuronas\n",
        "        - error de entrenamiento\n",
        "        - error de prueba\n",
        "        - diferencia entrenamiento y prueba  \n",
        "    \"\"\"\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for early_stop in is_early_stop:\n",
        "        for neurons in num_neurons:\n",
        "            #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "            # prestar atención a los parametros, correctos.\n",
        "            hidden_layer_sizes = tuple(2*[neurons])\n",
        "            mlp = MLPClassifier(... solver = 'sgd', random_state=1, tol = 1e-9)\n",
        "            mlp...(...)\n",
        "            # llamar la funcion creada anteriomente\n",
        "            error_train, error_test, diff = ...(Xtrain=..., \n",
        "                Ytrain=..., \n",
        "                Xtest=..., \n",
        "                Ytest=..., \n",
        "                sklearnModel=...)\n",
        "            resultados.loc[idx,'neuronas en capas ocultas'] = neurons \n",
        "            resultados.loc[idx,'error de entrenamiento'] = error_train\n",
        "            resultados.loc[idx,'error de prueba'] = ...\n",
        "            resultados.loc[idx,'diferencia entrenamiento y prueba'] = ...\n",
        "            resultados.loc[idx,'is_early_stop'] = early_stop\n",
        "            idx+=1\n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdbI_6iZTbEK"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio2\", exp_mlp_early_stop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmEqW2qgTbEM"
      },
      "outputs": [],
      "source": [
        "res_early_stop = exp_mlp_early_stop( [4,8,16], [True, False], x, x_test, y, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssdnLBHCTbEN"
      },
      "outputs": [],
      "source": [
        "sns.relplot(x = 'neuronas en capas ocultas', y='diferencia entrenamiento y prueba', hue = 'is_early_stop', data = res_early_stop, kind = 'line', aspect=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown Vuelve a revisar la documentacion de sklearn ¿que pasa cuando configuramos `n_iter_no_change=20` y la opción de parada anticipada?\n",
        "#@markdown ¿Cual de las opciones está mejor justificada?\n",
        " \n",
        "#@markdown A) Estamos duplicando el valor por defecto y hacemos que la parada anticipada sea menos estricta para determinar si el proceso de entrenamiento no mejora.\n",
        " \n",
        "#@markdown A) Estamos triplicando el valor por defecto y hacemos que la parada anticipada sea más estricta para determinar si el proceso de entrenamiento no mejora.\n",
        " \n",
        "#@markdown C) Estamos duplicando el valor por defecto y hacemos que la parada anticipada sea más estricta para determinar si el proceso de entrenamiento no mejora.\n",
        " \n",
        "#@markdown D)  Estamos duplicando el valor por defecto y hacemos que la parada anticipada se detenga en menos iteraciones.\n",
        " \n",
        "#@markdown Selecciona dentro las lista desplegable\n",
        "respuesta_4 = '' #@param [\"\", \"A\", \"B\", \"C\", \"D\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYhFhofwTbEP"
      },
      "source": [
        "Ahora vamos a experimentar con el parametro L2 del MLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5Rbf21WdTbEQ"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿explique en sus palabras en qué consiste la regularización L2?\n",
        "respuesta_5 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS6Sz86HTbER"
      },
      "outputs": [],
      "source": [
        "# ejercicio de código\n",
        "def exp_mlp_l2(num_neurons, l2_values, Xtrain,Xtest,Ytrain, Ytest):\n",
        "    \"\"\" función para realizar experimentos con el MLP con regularización L2\n",
        "\n",
        "    num_neurons: list de enteros con el numero de neuronas a usar\n",
        "    l2: list de floats con valores para regularizacion l2\n",
        "    Xtrain: matriz de numpy con caracteristicas de entrenamiento\n",
        "    Xtest: matriz de numpy con caracteristicas de prueba\n",
        "    ytrain: vector numpy con etiqueta de entrenamiento\n",
        "    ytest: vector numpy con etiqueta de prueba\n",
        "    \n",
        "    Retorna: dataframe con 5 columnas:\n",
        "        - numero de neuronas\n",
        "        - error de entrenamiento\n",
        "        - error de prueba\n",
        "        - diferencia entrenamiento y prueba  \n",
        "    \"\"\"\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for l2 in l2_values:\n",
        "        for neurons in num_neurons:\n",
        "            #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "            # prestar atención a los parametros, correctos.\n",
        "            hidden_layer_sizes = tuple(2*[neurons])\n",
        "            mlp = MLPClassifier(... , random_state=1, tol=1e-6, solver='sgd')\n",
        "            mlp...(...)\n",
        "            # llamar la funcion creada anteriomente\n",
        "            error_train, error_test, diff = ...(Xtrain=..., \n",
        "                Ytrain=..., \n",
        "                Xtest=..., \n",
        "                Ytest=..., \n",
        "                sklearnModel=..)\n",
        "            resultados.loc[idx,'neuronas en capas ocultas'] = neurons \n",
        "            resultados.loc[idx,'error de entrenamiento'] = ...\n",
        "            resultados.loc[idx,'error de prueba'] = ...\n",
        "            resultados.loc[idx,'diferencia entrenamiento y prueba'] = ...\n",
        "            resultados.loc[idx,'l2'] = l2\n",
        "            idx+=1\n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9WxvFIvTbEU"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio3\", exp_mlp_l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou3NnHTMTbEW"
      },
      "outputs": [],
      "source": [
        "res_l2 = exp_mlp_l2([4,16,64], [1e-3,1e-1,1e0, 1e1, 2e2, 1e3], x, x_test, y, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbiYggBzTbEY"
      },
      "outputs": [],
      "source": [
        "g=sns.relplot(x = 'l2', y='diferencia entrenamiento y prueba',\n",
        "            hue = 'neuronas en capas ocultas', \n",
        "            data = res_l2, kind = 'line', \n",
        "            aspect=2, \n",
        "            palette=sns.color_palette('viridis', n_colors=res_l2['neuronas en capas ocultas'].nunique()))\n",
        "\n",
        "g.set(xscale=\"log\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-iNKrRoTbEb"
      },
      "source": [
        "## Ejercicio 3 - Experimentar con regresión logistica regularizada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKRD9YADTbEb"
      },
      "source": [
        "Ahora vamos explorar la opciones de regularización de la regresión logistica. En la libreria se implementan más formas de regularizar, pero solo vamos a comprobar la regularización de norma L2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDooOislTbEd"
      },
      "outputs": [],
      "source": [
        "# ejercicio de código\n",
        "def exp_reg_l2(l2_values, Xtrain,Xtest,Ytrain, Ytest):\n",
        "    \"\"\" función para realizar experimentos con el MLP con early stopping\n",
        "    \n",
        "    l2_values: list de floats con valores para regularizacion l2\n",
        "    Xtrain: matriz de numpy con caracteristicas de entrenamiento\n",
        "    Xtest: matriz de numpy con caracteristicas de prueba\n",
        "    ytrain: vector numpy con etiqueta de entrenamiento\n",
        "    ytest: vector numpy con etiqueta de prueba\n",
        "    \n",
        "    \n",
        "    Retorna: dataframe con 5 columnas:\n",
        "        - numero de neuronas\n",
        "        - error de entrenamiento\n",
        "        - error de prueba\n",
        "        - diferencia entrenamiento y prueba  \n",
        "    \"\"\"\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for l2 in l2_values:\n",
        "        #Haga el llamado a la función para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "        # prestar atención a los parametros, correctos.\n",
        "        reg = LogisticRegression(..., random_state=1, tol = 1e-12)\n",
        "        reg....(...)\n",
        "        # llamar la funcion creada anteriomente\n",
        "        error_train, error_test, diff = ...(Xtrain=..., \n",
        "                Ytrain=..., \n",
        "                Xtest=..., \n",
        "                Ytest=..., \n",
        "                sklearnModel=...)\n",
        "        resultados.loc[idx,'error de entrenamiento'] = ...\n",
        "        resultados.loc[idx,'error de prueba'] = ...\n",
        "        resultados.loc[idx,'diferencia entrenamiento y prueba'] = ...\n",
        "        resultados.loc[idx,'l2'] = l2\n",
        "        idx+=1\n",
        "    return (resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5OPNTlITbEe"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio4\", exp_reg_l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWZIM72aTbEf"
      },
      "outputs": [],
      "source": [
        "reg_l2 = exp_reg_l2([1e-6,1e-3,1e-1,1e0, 1e1, 1e3], x, x_test, y, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNQ3fOPeTbEh"
      },
      "outputs": [],
      "source": [
        "g = sns.relplot(x = 'l2', y='diferencia entrenamiento y prueba',\n",
        "               data = reg_l2, kind = 'line', \n",
        "                aspect=2)\n",
        "\n",
        "g.set(xscale=\"log\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "i4weYXfHTbEj"
      },
      "outputs": [],
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown ¿qué efecto tiene el parametro que controla L2 en la regresión logistica en el overfitting? es diferente al MLP?\n",
        "respuesta_6 = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIAM660hTbEk"
      },
      "source": [
        "## Ejercicio 4 Efecto del tamaño del conjunto de entrenamiento\n",
        "\n",
        "Finalmente como mencionamos anteriormente, en los ejercicios que hemos resuelto, estabamos simulando la situación de un conjunto de datos de entrenamiento pequeño. En nuestro ultimo ejercicio vamos comprobar el efecto del tamaño del conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lh2LQUhTbEk"
      },
      "outputs": [],
      "source": [
        "# ejercicio de codigo\n",
        "def train_size_experiments(train_pcts,X,Y,sk_estimator):\n",
        "    \"\"\"funcion que realiza experimentos para\n",
        "        comprobar la influencia del tamaño de conjunto\n",
        "        de entrenamiento.\n",
        "    \n",
        "    train_pcts: lista de floats con los pct de entrenamiento a evaluar\n",
        "    X: matriz de numpy del conjunto de caracteristicas\n",
        "    Y: vector numpy con las etiquetas\n",
        "    sk_estimator: estimador/modelo de sklearn definido (sin entrenar)\n",
        "    \n",
        "    Retorna: dataframe con 5 columnas:\n",
        "        - tamaño del conjunto de entrenamiento\n",
        "        - error de entrenamiento\n",
        "        - error de prueba\n",
        "        - diferencia entrenamiento y prueba \n",
        "    \"\"\"\n",
        "    resultados = pd.DataFrame()\n",
        "    idx = 0\n",
        "    for train_pct in train_pcts:\n",
        "        #complete el con train_pct\n",
        "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=1-train_pct, \n",
        "                                                        random_state=10, stratify = Y)\n",
        "        scaler = StandardScaler().fit(Xtrain)\n",
        "        Xtrain = scaler.transform(Xtrain)\n",
        "        Xtest = scaler.transform(Xtest)\n",
        "        sk_estimator....(...)\n",
        "        # llamar la funcion creada anteriomente\n",
        "        error_train, error_test, diff = ...(Xtrain=..., \n",
        "                Ytrain=..., \n",
        "                Xtest=..., \n",
        "                Ytest=..., \n",
        "                sklearnModel=...)\n",
        "        resultados.loc[idx,'error de entrenamiento'] = ...\n",
        "        resultados.loc[idx,'error de prueba'] = ...\n",
        "        resultados.loc[idx,'diferencia entrenamiento y prueba'] = ...\n",
        "        resultados.loc[idx,'tamaño de entrenamiento'] = Xtrain.shape[0]\n",
        "        idx+=1\n",
        "    \n",
        "    return (resultados)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1VGs0OgTbEm"
      },
      "outputs": [],
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio5\", train_size_experiments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccI07QKMTbEp"
      },
      "outputs": [],
      "source": [
        "# comprobamos con un MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=[64,64], max_iter=1000, random_state=1)\n",
        "train_size_exp = train_size_experiments([0.2,0.3,0.5,0.7,0.9], x, y, mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxeHuXtnTbEr"
      },
      "outputs": [],
      "source": [
        "# vemos las tres medidas\n",
        "ax = train_size_exp.plot(x=\"tamaño de entrenamiento\", y=\"error de entrenamiento\", color=\"b\", legend=False, figsize = (9,6))\n",
        "train_size_exp.plot(x=\"tamaño de entrenamiento\", y=\"error de prueba\",  ax=ax, legend=False, color=\"r\")\n",
        "ax2 = ax.twinx()\n",
        "ax2.set_ylabel(\"diff train y test\")\n",
        "ax.set_ylabel(\"eficiencia\")\n",
        "train_size_exp.plot(x=\"tamaño de entrenamiento\", y=\"diferencia entrenamiento y prueba\", ax=ax2, legend=False, color=\"k\")\n",
        "ax.figure.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh_0RiBXTbEs"
      },
      "source": [
        "**Notas Finales** \n",
        "\n",
        "Para tener en cuenta: [Sklearn hay una libreria que realiza algo similar a lo que creamos en el anterior ejercicio.](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz3iJ10pTbEs"
      },
      "source": [
        "Debemos volver a recordar que en esta práctica exageramos algunas situaciones para lograr medir y ver el efecto del sobre-ajuste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKIT-LYSTbEt"
      },
      "outputs": [],
      "source": [
        "GRADER.check_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kJSs79rzTbEu"
      },
      "outputs": [],
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}\n",
        "codigo_integrante_2 = ''  #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBLsuTAtTbEw"
      },
      "source": [
        "----\n",
        "esta linea de codigo va fallar, es de uso exclusivo de los profesores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhZOwh83TbEw"
      },
      "outputs": [],
      "source": [
        "GRADER.grade()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab4_parte2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('udea')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c216c800eb90efed5b4e7fbe9fb3a04a2ffbc3fe33e223430d52baede0ec7928"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
